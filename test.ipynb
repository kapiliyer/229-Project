{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from random import sample\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "for folder in ['multitask', 'para_single', 'sts_single', 'multitask_pcgrad', 'multitask_gradnorm', 'multitask_cagrad']:\n",
    "    try:\n",
    "        os.mkdir('./models/' + folder)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "sts_train = pd.read_csv('./data/sts-train.csv', sep=\"\\t\")\n",
    "sts_train = sts_train.dropna()\n",
    "\n",
    "para_train = pd.read_csv('./data/quora-train.csv', sep=\"\\t\")\n",
    "para_train = para_train.dropna()[:len(sts_train)]\n",
    "\n",
    "sts_dev = pd.read_csv('./data/sts-dev.csv', sep=\"\\t\")\n",
    "sts_dev = sts_dev.dropna() \n",
    "\n",
    "para_dev = pd.read_csv('./data/quora-dev.csv', sep=\"\\t\")\n",
    "para_dev = para_dev.dropna()[:len(sts_dev)]\n",
    "\n",
    "sts_combined_set = pd.concat([sts_train, sts_dev], ignore_index=True, axis=0)\n",
    "para_combined_set = pd.concat([para_train, para_dev], ignore_index=True, axis=0)\n",
    "\n",
    "sts_train, sts_dev = train_test_split(sts_combined_set, test_size=0.3, train_size=0.7, shuffle=False)\n",
    "sts_dev, sts_test = train_test_split(sts_dev, test_size=0.5, train_size=0.5, shuffle=False)\n",
    "para_train, para_dev = train_test_split(para_combined_set, test_size=0.3, train_size=0.7, shuffle=False)\n",
    "para_dev, para_test = train_test_split(para_dev, test_size=0.5, train_size=0.5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "# sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "# model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "# embeddings = model.encode(sentences)\n",
    "# print(embeddings)\n",
    "# print(para_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "N_PARAPHRASE_CLASSES = 1\n",
    "N_SIMILARITY_CLASSES = 1\n",
    "DROPOUT_PROB = 0.5\n",
    "INPUT_SIZE = 768\n",
    "\n",
    "class NLP_Model(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(NLP_Model, self).__init__()\n",
    "        self.model = model\n",
    "        self.dropout = nn.Dropout(DROPOUT_PROB)\n",
    "        self.paraphrase_linear = nn.Linear(INPUT_SIZE, INPUT_SIZE // 2)\n",
    "        self.paraphrase_linear_interact = nn.Linear(INPUT_SIZE, N_PARAPHRASE_CLASSES)\n",
    "        self.similarity_linear = nn.Linear(INPUT_SIZE, INPUT_SIZE // 2)\n",
    "        self.similarity_linear_interact = nn.Linear(INPUT_SIZE, N_SIMILARITY_CLASSES)\n",
    "    \n",
    "    def forward(self, sentences1, sentences2, task, device):\n",
    "        '''\n",
    "        Task 0 is para. Task 1 is similarity.\n",
    "        '''\n",
    "        sentences1 = torch.as_tensor(self.model.encode(sentences1.tolist()))\n",
    "        sentences1 = sentences1.to(device)\n",
    "        sentences2 = torch.as_tensor(self.model.encode(sentences2.tolist()))\n",
    "        sentences2 = sentences2.to(device)\n",
    "        if task == 0:\n",
    "            sentences1 = self.dropout(sentences1)\n",
    "            sentences1 = F.relu(self.paraphrase_linear(sentences1))\n",
    "            sentences2 = self.dropout(sentences2)\n",
    "            sentences2 = F.relu(self.paraphrase_linear(sentences2))\n",
    "            combined = torch.concat((sentences1, sentences2), dim=-1)\n",
    "            combined = self.dropout(combined)\n",
    "            return F.sigmoid(self.paraphrase_linear_interact(combined))\n",
    "        if task == 1:\n",
    "            sentences1 = self.dropout(sentences1)\n",
    "            sentences1 = F.relu(self.similarity_linear(sentences1))\n",
    "            sentences2 = self.dropout(sentences2)\n",
    "            sentences2 = F.relu(self.similarity_linear(sentences2))\n",
    "            combined = torch.concat((sentences1, sentences2), dim=-1)\n",
    "            combined = self.dropout(combined)\n",
    "            return F.sigmoid(self.similarity_linear_interact(combined)) * 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "def save_model(model, filepath):\n",
    "    save_info = {\n",
    "        'model': model.state_dict(),\n",
    "        'system_rng': random.getstate(),\n",
    "        'numpy_rng': np.random.get_state(),\n",
    "        'torch_rng': torch.random.get_rng_state(),\n",
    "    }\n",
    "\n",
    "    torch.save(save_info, f'{filepath}/model')\n",
    "    model.model.save(f'{filepath}/transformer')\n",
    "    print(f\"saved the model to {filepath}\")\n",
    "\n",
    "def load_model(filepath, device):\n",
    "    with torch.no_grad():\n",
    "        save_info = torch.load(f'{filepath}/model')\n",
    "        transformer_model = SentenceTransformer(f'{filepath}/transformer')\n",
    "        transformer_model.to(device)\n",
    "        \n",
    "        model = NLP_Model(transformer_model)\n",
    "        model.load_state_dict(save_info['model'])\n",
    "        model.to(device)\n",
    "        \n",
    "        random.setstate(save_info['system_rng'])\n",
    "        np.random.set_state(save_info['numpy_rng'])\n",
    "        torch.random.set_rng_state(save_info['torch_rng'])\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "def get_batches(dataset, batch_size=512):\n",
    "    \"\"\"\n",
    "    Pass in dataset and batch size.\n",
    "    Get generator which yields batches.\n",
    "    \"\"\"\n",
    "    return enumerate(dataset[i*batch_size:(i+1)*batch_size] for i in range(ceil(dataset.shape[0] / batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "NUM_EPOCHS = 30\n",
    "\n",
    "def train_singletask_para_model(para_train, para_dev, filepath):\n",
    "    '''\n",
    "    use AdamW optimizer.\n",
    "    binary cross-entropy loss.\n",
    "    make sure to save model at end to a specific path.\n",
    "    '''\n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "    transformer = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "    transformer.to(device)\n",
    "\n",
    "    model = NLP_Model(transformer)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = AdamW(list(model.parameters()) + list(transformer.parameters()), lr=1e-2) #~SGD with weight decay 0.01\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'max')\n",
    "\n",
    "    best_dev_acc = 0\n",
    "\n",
    "    train_para_accuracy = eval_singletask_model(model, device, para_train, 0, 'train')\n",
    "    dev_para_accuracy = eval_singletask_model(model, device, para_dev, 0, 'dev')\n",
    "    print(f\"epoch number: 0, para train accuracy: {train_para_accuracy}, para dev accuracy: {dev_para_accuracy}\")\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        transformer.train()\n",
    "\n",
    "        for step, batch in tqdm(get_batches(para_train), desc='train'):\n",
    "            b_sentences1, b_sentences2, b_labels = batch['sentence1'], batch['sentence2'], batch['is_duplicate']\n",
    "            optimizer.zero_grad()\n",
    "            logits = model.forward(b_sentences1, b_sentences2, 0, device).flatten()\n",
    "\n",
    "            b_labels = torch.as_tensor(b_labels.values, dtype=torch.float32)\n",
    "            b_labels = b_labels.to(device)\n",
    "\n",
    "            loss = F.binary_cross_entropy(logits, b_labels, reduction='mean')\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_para_accuracy = eval_singletask_model(model, device, para_train, 0, 'train')\n",
    "        dev_para_accuracy = eval_singletask_model(model, device, para_dev, 0, 'dev')\n",
    "        print(f\"epoch number: {epoch + 1}, para train accuracy: {train_para_accuracy}, para dev accuracy: {dev_para_accuracy}\")\n",
    "\n",
    "        scheduler.step(dev_para_accuracy)\n",
    "\n",
    "        if dev_para_accuracy >= best_dev_acc:\n",
    "            best_dev_acc = dev_para_accuracy\n",
    "            print('New best model. Saving.')\n",
    "            save_model(model, filepath)\n",
    "\n",
    "\n",
    "def train_singletask_sts_model(sts_train, sts_dev, filepath):\n",
    "    '''\n",
    "    use AdamW optimizer.\n",
    "    multi-class cross-entropy loss.\n",
    "    make sure to save model at end to a specific path.\n",
    "    '''\n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "    transformer = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "    transformer.to(device)\n",
    "\n",
    "    model = NLP_Model(transformer)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = AdamW(list(model.parameters()) + list(transformer.parameters()), lr=1e-2) #~SGD with weight decay 0.01\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'max')\n",
    "\n",
    "    best_dev_acc = 0\n",
    "\n",
    "    train_sts_acc = eval_singletask_model(model, device, sts_train, 1, 'train')\n",
    "    dev_sts_acc = eval_singletask_model(model, device, sts_dev, 1, 'dev')\n",
    "    print(f\"epoch number: 0, sts train accuracy: {train_sts_acc}, sts dev accuracy: {dev_sts_acc}\")\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        transformer.train()\n",
    "\n",
    "        for step, batch in tqdm(get_batches(sts_train), desc='train'):\n",
    "            b_sentences1, b_sentences2, b_labels = batch['sentence1'], batch['sentence2'], batch['similarity']\n",
    "            optimizer.zero_grad()\n",
    "            logits = model.forward(b_sentences1, b_sentences2, 1, device).flatten()\n",
    "\n",
    "            b_labels = torch.as_tensor(b_labels.values, dtype=torch.float32)\n",
    "            b_labels = b_labels.to(device)\n",
    "\n",
    "            loss = F.mse_loss(logits, b_labels, reduction='mean')\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_sts_acc = eval_singletask_model(model, device, sts_train, 1, 'train')\n",
    "        dev_sts_acc = eval_singletask_model(model, device, sts_dev, 1, 'dev')\n",
    "        print(f\"epoch number: {epoch + 1}, sts train accuracy: {train_sts_acc}, sts dev accuracy: {dev_sts_acc}\")\n",
    "\n",
    "        scheduler.step(dev_sts_acc)\n",
    "\n",
    "        if dev_sts_acc >= best_dev_acc:\n",
    "            best_dev_acc = dev_sts_acc\n",
    "            print('New best model. Saving.')\n",
    "            save_model(model, filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/docs/transformers/training#train-in-native-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_singletask_model(model, device, dataset, task, flag):\n",
    "    '''\n",
    "    given dataloader, 2 task-specific finetuned models, and device\n",
    "    return the accuracy for para and for sts\n",
    "    '''\n",
    "    model.eval()\n",
    "    model.model.eval()\n",
    "    with torch.no_grad():\n",
    "        truth = []\n",
    "        predictions = []\n",
    "        for step, batch in tqdm(get_batches(dataset), desc=f\"{flag} eval\"):\n",
    "            b_sentences1, b_sentences2, b_labels = batch['sentence1'], batch['sentence2'], batch['is_duplicate' if task == 0 else 'similarity']\n",
    "            truth.extend(b_labels)\n",
    "            logits = model.forward(b_sentences1, b_sentences2, task, device)\n",
    "            logits = logits.detach().cpu().numpy().flatten()\n",
    "            if task == 0:\n",
    "                new_predictions = np.round(logits).flatten()\n",
    "            else:\n",
    "                new_predictions = logits.flatten()\n",
    "            predictions.extend(new_predictions)\n",
    "        if task == 0:\n",
    "            accuracy = (np.array(truth).flatten() == np.array(predictions).flatten()).mean()\n",
    "        else:\n",
    "            accuracy = (np.round(np.array(truth).flatten()) == np.round(np.array(predictions).flatten())).mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcgrad import PCGrad\n",
    "\n",
    "def train_multitask_model(para_train, para_dev, sts_train, sts_dev, filepath, pcgrad_flag):\n",
    "    '''\n",
    "    use AdamW optimizer.\n",
    "    binary cross-entropy loss for para, multi-class cross-entropy loss for sts, sum loss functions. \n",
    "    make sure to save model at end to a specific path.\n",
    "    '''\n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "    transformer = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "    transformer.to(device)\n",
    "\n",
    "    model = NLP_Model(transformer)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = AdamW(list(model.parameters()) + list(transformer.parameters()), lr=1e-2) #~SGD with weight decay 0.01\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "    if pcgrad_flag: optimizer = PCGrad(optimizer)\n",
    "\n",
    "    best_dev_acc = 0\n",
    "\n",
    "    train_para_acc = eval_singletask_model(model, device, para_train, 0, 'train')\n",
    "    dev_para_acc = eval_singletask_model(model, device, para_dev, 0, 'dev')\n",
    "    train_sts_acc = eval_singletask_model(model, device, sts_train, 1, 'train')\n",
    "    dev_sts_acc = eval_singletask_model(model, device, sts_dev, 1, 'dev')\n",
    "    print(f\"epoch number: 0, para train accuracy: {train_para_acc}, para dev accuracy: {dev_para_acc}, sts train accuracy: {train_sts_acc}, sts dev accuracy: {dev_sts_acc}\")\n",
    "\n",
    "    train_acc = (train_para_acc + train_sts_acc) / 2\n",
    "    dev_acc = (dev_para_acc + dev_sts_acc) / 2\n",
    "    print(f\"epoch number: 0, avg train accuracy: {train_acc}, avg dev accuracy: {dev_acc}\")\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        transformer.train()\n",
    "\n",
    "        for (para_step, para_batch), (sts_step, sts_batch) in zip(tqdm(get_batches(para_train), desc='train'), tqdm(get_batches(sts_train), desc='train')):\n",
    "            b_para_sentences1, b_para_sentences2, b_para_labels = para_batch['sentence1'], para_batch['sentence2'], para_batch['is_duplicate']\n",
    "            b_sts_sentences1, b_sts_sentences2, b_sts_labels = sts_batch['sentence1'], sts_batch['sentence2'], sts_batch['similarity']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            para_logits = model.forward(b_para_sentences1, b_para_sentences2, 0, device).flatten()\n",
    "            sts_logits = model.forward(b_sts_sentences1, b_sts_sentences2, 1, device).flatten()\n",
    "\n",
    "            b_para_labels = torch.as_tensor(b_para_labels.values, dtype=torch.float32)\n",
    "            b_para_labels = b_para_labels.to(device)\n",
    "            b_sts_labels = torch.as_tensor(b_sts_labels.values, dtype=torch.float32)\n",
    "            b_sts_labels = b_sts_labels.to(device)\n",
    "\n",
    "            loss = (F.binary_cross_entropy(para_logits, b_para_labels, reduction='mean') + F.mse_loss(sts_logits, b_sts_labels, reduction='mean')) / 2\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_para_acc = eval_singletask_model(model, device, para_train, 0, 'train')\n",
    "        dev_para_acc = eval_singletask_model(model, device, para_dev, 0, 'dev')\n",
    "        train_sts_acc = eval_singletask_model(model, device, sts_train, 1, 'train')\n",
    "        dev_sts_acc = eval_singletask_model(model, device, sts_dev, 1, 'dev')\n",
    "        print(f\"epoch number: {epoch + 1}, para train accuracy: {train_para_acc}, para dev accuracy: {dev_para_acc}, sts train accuracy: {train_sts_acc}, sts dev accuracy: {dev_sts_acc}\")\n",
    "\n",
    "        train_acc = (train_para_acc + train_sts_acc) / 2\n",
    "        dev_acc = (dev_para_acc + dev_sts_acc) / 2\n",
    "        print(f\"epoch number: {epoch + 1}, avg train accuracy: {train_acc}, avg dev accuracy: {dev_acc}\")\n",
    "\n",
    "        scheduler.step(dev_acc, 'max')\n",
    "\n",
    "        if dev_acc >= best_dev_acc:\n",
    "            best_dev_acc = dev_acc\n",
    "            print('New best model. Saving.')\n",
    "            save_model(model, filepath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multitask_model_gradnorm(para_train, para_dev, sts_train, sts_dev, filepath, alpha, layer):\n",
    "    '''\n",
    "    use AdamW optimizer.\n",
    "    binary cross-entropy loss for para, multi-class cross-entropy loss for sts, sum loss functions. \n",
    "    make sure to save model at end to a specific path.\n",
    "    '''\n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "    transformer = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "    transformer.to(device)\n",
    "\n",
    "    model = NLP_Model(transformer)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = AdamW(list(model.parameters()) + list(transformer.parameters()), lr=1e-2) #~SGD with weight decay 0.01\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "\n",
    "    best_dev_acc = 0\n",
    "\n",
    "    train_para_acc = eval_singletask_model(model, device, para_train, 0, 'train')\n",
    "    dev_para_acc = eval_singletask_model(model, device, para_dev, 0, 'dev')\n",
    "    train_sts_acc = eval_singletask_model(model, device, sts_train, 1, 'train')\n",
    "    dev_sts_acc = eval_singletask_model(model, device, sts_dev, 1, 'dev')\n",
    "    print(f\"epoch number: 0, para train accuracy: {train_para_acc}, para dev accuracy: {dev_para_acc}, sts train accuracy: {train_sts_acc}, sts dev accuracy: {dev_sts_acc}\")\n",
    "\n",
    "    train_acc = (train_para_acc + train_sts_acc) / 2\n",
    "    dev_acc = (dev_para_acc + dev_sts_acc) / 2\n",
    "    print(f\"epoch number: 0, avg train accuracy: {train_acc}, avg dev accuracy: {dev_acc}\")\n",
    "\n",
    "    iters = 0\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        transformer.train()\n",
    "\n",
    "        for (para_step, para_batch), (sts_step, sts_batch) in zip(tqdm(get_batches(para_train), desc='train'), tqdm(get_batches(sts_train), desc='train')):\n",
    "            b_para_sentences1, b_para_sentences2, b_para_labels = para_batch['sentence1'], para_batch['sentence2'], para_batch['is_duplicate']\n",
    "            b_sts_sentences1, b_sts_sentences2, b_sts_labels = sts_batch['sentence1'], sts_batch['sentence2'], sts_batch['similarity']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            para_logits = model.forward(b_para_sentences1, b_para_sentences2, 0, device).flatten()\n",
    "            sts_logits = model.forward(b_sts_sentences1, b_sts_sentences2, 1, device).flatten()\n",
    "\n",
    "            b_para_labels = torch.as_tensor(b_para_labels.values, dtype=torch.float32)\n",
    "            b_para_labels = b_para_labels.to(device)\n",
    "            b_sts_labels = torch.as_tensor(b_sts_labels.values, dtype=torch.float32)\n",
    "            b_sts_labels = b_sts_labels.to(device)\n",
    "\n",
    "            loss = (F.binary_cross_entropy(para_logits, b_para_labels, reduction='mean') + F.mse_loss(sts_logits, b_sts_labels, reduction='mean')) / 2\n",
    "            if iters == 0:\n",
    "                weights = torch.ones_like(loss)\n",
    "                weights = torch.nn.Parameter(weights)\n",
    "                T = weights.sum().detach()\n",
    "                optimizer2 = torch.optim.Adam([weights], lr=1e-2)\n",
    "                l0 = loss.detach()\n",
    "            weighted_loss = np.dot(weights, loss)\n",
    "            weighted_loss.backward()\n",
    "            gradient_weights = []\n",
    "            for i in range(len(loss)):\n",
    "                d_l = torch.autograd.grad(weights[i] * loss[i], layer.parameters())[0]\n",
    "                gradient_weights.append(torch.norm(d_l))\n",
    "            gradient_weights = torch.stack(gradient_weights)\n",
    "            lossratio = loss.detach() / l0\n",
    "            r_t = lossratio / lossratio.mean()\n",
    "            avg_gradient_weight = gradient_weights.mean().detach()\n",
    "            const_factor = (avg_gradient_weight * r_t ** alpha).detach()\n",
    "            gradnormloss = torch.abs(gradient_weights - const_factor).sum()\n",
    "            optimizer2.zero_grad()\n",
    "            gradnormloss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer2.step()\n",
    "            weights = (weights / weights.sum() * T).detach()\n",
    "            weights = torch.nn.Parameter(weights)\n",
    "            optimizer2 = torch.optim.Adam([weights], lr=1e-2)\n",
    "            iters += 1\n",
    "\n",
    "        train_para_acc = eval_singletask_model(model, device, para_train, 0, 'train')\n",
    "        dev_para_acc = eval_singletask_model(model, device, para_dev, 0, 'dev')\n",
    "        train_sts_acc = eval_singletask_model(model, device, sts_train, 1, 'train')\n",
    "        dev_sts_acc = eval_singletask_model(model, device, sts_dev, 1, 'dev')\n",
    "        print(f\"epoch number: {epoch + 1}, para train accuracy: {train_para_acc}, para dev accuracy: {dev_para_acc}, sts train accuracy: {train_sts_acc}, sts dev accuracy: {dev_sts_acc}\")\n",
    "\n",
    "        train_acc = (train_para_acc + train_sts_acc) / 2\n",
    "        dev_acc = (dev_para_acc + dev_sts_acc) / 2\n",
    "        print(f\"epoch number: {epoch + 1}, avg train accuracy: {train_acc}, avg dev accuracy: {dev_acc}\")\n",
    "\n",
    "        scheduler.step(dev_acc, 'max')\n",
    "\n",
    "        if dev_acc >= best_dev_acc:\n",
    "            best_dev_acc = dev_acc\n",
    "            print('New best model. Saving.')\n",
    "            save_model(model, filepath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_singletask_model(filepath1, filepath2):\n",
    "    train_singletask_para_model(para_train, para_dev, filepath1)\n",
    "    train_singletask_sts_model(sts_train, sts_dev, filepath2)\n",
    "\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "    para_model, _ = load_model(filepath1, device)\n",
    "    sts_model, _ = load_model(filepath2, device)\n",
    "\n",
    "    para_acc = eval_singletask_model(para_model, device, para_test, 0, 'test')\n",
    "    sts_acc = eval_singletask_model(sts_model, device, sts_test, 1, 'test')\n",
    "\n",
    "    print(f'Final test accuracy. PARA: {para_acc}, STS: {sts_acc}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_singletask_model('./models/para_single', './models/sts_single')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_multitask_model(filepath, pcgrad_flag):\n",
    "    train_multitask_model(para_train, para_dev, sts_train, sts_dev, filepath, pcgrad_flag)\n",
    "\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "    model, _ = load_model(filepath, device)\n",
    "\n",
    "    para_acc = eval_singletask_model(model, device, para_test, 0, 'test')\n",
    "    sts_acc = eval_singletask_model(model, device, sts_test, 1, 'test')\n",
    "\n",
    "    print(f'Final test accuracy. PARA: {para_acc}, STS: {sts_acc}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train eval: 1it [00:01,  1.38s/it]\n",
      "dev eval: 1it [00:00,  3.25it/s]\n",
      "train eval: 1it [00:01,  1.28s/it]\n",
      "dev eval: 1it [00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 0, para train accuracy: 0.36007827788649704, para dev accuracy: 0.36363636363636365, sts train accuracy: 0.1643835616438356, sts dev accuracy: 0.19090909090909092\n",
      "epoch number: 0, avg train accuracy: 0.2622309197651663, avg dev accuracy: 0.2772727272727273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:02,  2.69s/it]\n",
      "train: 0it [00:02, ?it/s]\n",
      "train eval: 1it [00:01,  1.39s/it]\n",
      "dev eval: 1it [00:00,  3.19it/s]\n",
      "train eval: 1it [00:01,  1.29s/it]\n",
      "dev eval: 1it [00:00,  3.24it/s]\n",
      "/opt/conda/envs/cs229/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:1013: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 1, para train accuracy: 0.649706457925636, para dev accuracy: 0.6363636363636364, sts train accuracy: 0.2172211350293542, sts dev accuracy: 0.23636363636363636\n",
      "epoch number: 1, avg train accuracy: 0.4334637964774951, avg dev accuracy: 0.43636363636363634\n",
      "New best model. Saving.\n",
      "saved the model to ./models/multitask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:02,  2.68s/it]\n",
      "train: 0it [00:02, ?it/s]\n",
      "train eval: 1it [00:01,  1.39s/it]\n",
      "dev eval: 1it [00:00,  3.16it/s]\n",
      "train eval: 1it [00:01,  1.29s/it]\n",
      "dev eval: 1it [00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 2, para train accuracy: 0.7103718199608611, para dev accuracy: 0.6818181818181818, sts train accuracy: 0.2054794520547945, sts dev accuracy: 0.18181818181818182\n",
      "epoch number: 2, avg train accuracy: 0.45792563600782776, avg dev accuracy: 0.43181818181818177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:02,  2.67s/it]\n",
      "train: 0it [00:02, ?it/s]\n",
      "train eval: 1it [00:01,  1.38s/it]\n",
      "dev eval: 1it [00:00,  3.20it/s]\n",
      "train eval: 1it [00:01,  1.29s/it]\n",
      "dev eval: 1it [00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 3, para train accuracy: 0.7925636007827789, para dev accuracy: 0.7272727272727273, sts train accuracy: 0.26418786692759294, sts dev accuracy: 0.2636363636363636\n",
      "epoch number: 3, avg train accuracy: 0.5283757338551859, avg dev accuracy: 0.4954545454545455\n",
      "New best model. Saving.\n",
      "saved the model to ./models/multitask\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:02,  2.70s/it]\n",
      "train: 0it [00:02, ?it/s]\n",
      "train eval: 1it [00:01,  1.38s/it]\n",
      "dev eval: 1it [00:00,  3.19it/s]\n",
      "train eval: 1it [00:01,  1.27s/it]\n",
      "dev eval: 1it [00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 4, para train accuracy: 0.8160469667318982, para dev accuracy: 0.7090909090909091, sts train accuracy: 0.2857142857142857, sts dev accuracy: 0.2\n",
      "epoch number: 4, avg train accuracy: 0.550880626223092, avg dev accuracy: 0.4545454545454546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:02,  2.66s/it]\n",
      "train: 0it [00:02, ?it/s]\n",
      "train eval: 1it [00:01,  1.40s/it]\n",
      "dev eval: 1it [00:00,  3.24it/s]\n",
      "train eval: 1it [00:01,  1.30s/it]\n",
      "dev eval: 1it [00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 5, para train accuracy: 0.8199608610567515, para dev accuracy: 0.7, sts train accuracy: 0.2974559686888454, sts dev accuracy: 0.2545454545454545\n",
      "epoch number: 5, avg train accuracy: 0.5587084148727984, avg dev accuracy: 0.47727272727272724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:02,  2.71s/it]\n",
      "train: 0it [00:02, ?it/s]\n",
      "train eval: 1it [00:01,  1.41s/it]\n",
      "dev eval: 1it [00:00,  3.20it/s]\n",
      "train eval: 1it [00:01,  1.32s/it]\n",
      "dev eval: 1it [00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 6, para train accuracy: 0.8395303326810176, para dev accuracy: 0.6818181818181818, sts train accuracy: 0.30332681017612523, sts dev accuracy: 0.2727272727272727\n",
      "epoch number: 6, avg train accuracy: 0.5714285714285714, avg dev accuracy: 0.47727272727272724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:02,  2.73s/it]\n",
      "train: 0it [00:02, ?it/s]\n",
      "train eval: 1it [00:01,  1.41s/it]\n",
      "dev eval: 1it [00:00,  3.20it/s]\n",
      "train eval: 1it [00:01,  1.32s/it]\n",
      "dev eval: 1it [00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 7, para train accuracy: 0.8551859099804305, para dev accuracy: 0.6818181818181818, sts train accuracy: 0.3268101761252446, sts dev accuracy: 0.2545454545454545\n",
      "epoch number: 7, avg train accuracy: 0.5909980430528375, avg dev accuracy: 0.46818181818181814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:02,  2.74s/it]\n",
      "train: 0it [00:02, ?it/s]\n",
      "train eval: 1it [00:01,  1.43s/it]\n",
      "dev eval: 1it [00:00,  3.08it/s]\n",
      "train eval: 1it [00:01,  1.32s/it]\n",
      "dev eval: 1it [00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 8, para train accuracy: 0.8688845401174168, para dev accuracy: 0.6454545454545455, sts train accuracy: 0.37377690802348335, sts dev accuracy: 0.2727272727272727\n",
      "epoch number: 8, avg train accuracy: 0.6213307240704501, avg dev accuracy: 0.4590909090909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:02,  2.74s/it]\n",
      "train: 0it [00:02, ?it/s]\n",
      "train eval: 1it [00:01,  1.42s/it]\n",
      "dev eval: 1it [00:00,  3.18it/s]\n",
      "train eval: 1it [00:01,  1.32s/it]\n",
      "dev eval: 1it [00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 9, para train accuracy: 0.8943248532289628, para dev accuracy: 0.6636363636363637, sts train accuracy: 0.41487279843444225, sts dev accuracy: 0.2818181818181818\n",
      "epoch number: 9, avg train accuracy: 0.6545988258317026, avg dev accuracy: 0.4727272727272728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:02,  2.71s/it]\n",
      "train: 0it [00:02, ?it/s]\n",
      "train eval: 1it [00:01,  1.40s/it]\n",
      "dev eval: 1it [00:00,  3.22it/s]\n",
      "train eval: 1it [00:01,  1.30s/it]\n",
      "dev eval: 1it [00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 10, para train accuracy: 0.9412915851272016, para dev accuracy: 0.6636363636363637, sts train accuracy: 0.4520547945205479, sts dev accuracy: 0.23636363636363636\n",
      "epoch number: 10, avg train accuracy: 0.6966731898238747, avg dev accuracy: 0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:02,  2.67s/it]\n",
      "train: 0it [00:02, ?it/s]\n",
      "train eval: 1it [00:01,  1.38s/it]\n",
      "dev eval: 1it [00:00,  3.19it/s]\n",
      "train eval: 1it [00:01,  1.29s/it]\n",
      "dev eval: 1it [00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 11, para train accuracy: 0.9608610567514677, para dev accuracy: 0.6454545454545455, sts train accuracy: 0.4598825831702544, sts dev accuracy: 0.19090909090909092\n",
      "epoch number: 11, avg train accuracy: 0.7103718199608611, avg dev accuracy: 0.4181818181818182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:02,  2.68s/it]\n",
      "train: 0it [00:02, ?it/s]\n",
      "train eval: 1it [00:01,  1.38s/it]\n",
      "dev eval: 1it [00:00,  3.17it/s]\n",
      "train eval: 1it [00:01,  1.29s/it]\n",
      "dev eval: 1it [00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 12, para train accuracy: 0.9726027397260274, para dev accuracy: 0.6636363636363637, sts train accuracy: 0.5264187866927593, sts dev accuracy: 0.21818181818181817\n",
      "epoch number: 12, avg train accuracy: 0.7495107632093934, avg dev accuracy: 0.4409090909090909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:02,  2.67s/it]\n",
      "train: 0it [00:02, ?it/s]\n",
      "train eval: 1it [00:01,  1.39s/it]\n",
      "dev eval: 1it [00:00,  3.19it/s]\n",
      "train eval: 1it [00:01,  1.29s/it]\n",
      "dev eval: 1it [00:00,  3.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 13, para train accuracy: 0.974559686888454, para dev accuracy: 0.6454545454545455, sts train accuracy: 0.6007827788649707, sts dev accuracy: 0.24545454545454545\n",
      "epoch number: 13, avg train accuracy: 0.7876712328767124, avg dev accuracy: 0.4454545454545455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:02,  2.66s/it]\n",
      "train: 0it [00:02, ?it/s]\n",
      "train eval: 1it [00:01,  1.39s/it]\n",
      "dev eval: 1it [00:00,  3.20it/s]\n",
      "train eval: 1it [00:01,  1.29s/it]\n",
      "dev eval: 1it [00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 14, para train accuracy: 0.9784735812133072, para dev accuracy: 0.6454545454545455, sts train accuracy: 0.6105675146771037, sts dev accuracy: 0.24545454545454545\n",
      "epoch number: 14, avg train accuracy: 0.7945205479452054, avg dev accuracy: 0.4454545454545455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:02,  2.67s/it]\n",
      "train: 0it [00:02, ?it/s]\n",
      "train eval: 1it [00:01,  1.39s/it]\n",
      "dev eval: 1it [00:00,  3.22it/s]\n",
      "train eval: 1it [00:01,  1.27s/it]\n",
      "dev eval: 1it [00:00,  3.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 15, para train accuracy: 0.9902152641878669, para dev accuracy: 0.6454545454545455, sts train accuracy: 0.5792563600782779, sts dev accuracy: 0.2\n",
      "epoch number: 15, avg train accuracy: 0.7847358121330723, avg dev accuracy: 0.42272727272727273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:02,  2.66s/it]\n",
      "train: 0it [00:02, ?it/s]\n",
      "train eval: 1it [00:01,  1.38s/it]\n",
      "dev eval: 1it [00:00,  3.21it/s]\n",
      "train eval: 1it [00:01,  1.28s/it]\n",
      "dev eval: 1it [00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 16, para train accuracy: 0.9921722113502935, para dev accuracy: 0.6454545454545455, sts train accuracy: 0.639921722113503, sts dev accuracy: 0.2\n",
      "epoch number: 16, avg train accuracy: 0.8160469667318982, avg dev accuracy: 0.42272727272727273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:02,  2.66s/it]\n",
      "train: 0it [00:02, ?it/s]\n",
      "train eval: 1it [00:01,  1.39s/it]\n",
      "dev eval: 1it [00:00,  3.20it/s]\n",
      "train eval: 1it [00:01,  1.29s/it]\n",
      "dev eval: 1it [00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 17, para train accuracy: 0.9960861056751468, para dev accuracy: 0.6545454545454545, sts train accuracy: 0.7045009784735812, sts dev accuracy: 0.2636363636363636\n",
      "epoch number: 17, avg train accuracy: 0.850293542074364, avg dev accuracy: 0.4590909090909091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:02,  2.68s/it]\n",
      "train: 0it [00:02, ?it/s]\n",
      "train eval: 1it [00:01,  1.38s/it]\n",
      "dev eval: 1it [00:00,  3.20it/s]\n",
      "train eval: 1it [00:01,  1.29s/it]\n",
      "dev eval: 1it [00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 18, para train accuracy: 0.9960861056751468, para dev accuracy: 0.6454545454545455, sts train accuracy: 0.6986301369863014, sts dev accuracy: 0.24545454545454545\n",
      "epoch number: 18, avg train accuracy: 0.8473581213307241, avg dev accuracy: 0.4454545454545455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:02,  2.68s/it]\n",
      "train: 0it [00:02, ?it/s]\n",
      "train eval: 1it [00:01,  1.39s/it]\n",
      "dev eval: 1it [00:00,  3.21it/s]\n",
      "train eval: 1it [00:01,  1.29s/it]\n",
      "dev eval: 1it [00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 19, para train accuracy: 0.9960861056751468, para dev accuracy: 0.6545454545454545, sts train accuracy: 0.6908023483365949, sts dev accuracy: 0.22727272727272727\n",
      "epoch number: 19, avg train accuracy: 0.8434442270058709, avg dev accuracy: 0.4409090909090909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:02,  2.69s/it]\n",
      "train: 0it [00:02, ?it/s]\n",
      "train eval: 1it [00:01,  1.39s/it]\n",
      "dev eval: 1it [00:00,  3.19it/s]\n",
      "train eval: 1it [00:01,  1.30s/it]\n",
      "dev eval: 1it [00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 20, para train accuracy: 0.9960861056751468, para dev accuracy: 0.6454545454545455, sts train accuracy: 0.7162426614481409, sts dev accuracy: 0.22727272727272727\n",
      "epoch number: 20, avg train accuracy: 0.8561643835616438, avg dev accuracy: 0.4363636363636364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test eval: 1it [00:00,  3.35it/s]\n",
      "test eval: 1it [00:00,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test accuracy. PARA: 0.6454545454545455, STS: 0.2636363636363636.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_multitask_model('./models/multitask', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train eval: 1it [00:01,  1.40s/it]\n",
      "dev eval: 1it [00:00,  3.26it/s]\n",
      "train eval: 1it [00:01,  1.25s/it]\n",
      "dev eval: 1it [00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 0, para train accuracy: 0.649706457925636, para dev accuracy: 0.6363636363636364, sts train accuracy: 0.2035225048923679, sts dev accuracy: 0.21818181818181817\n",
      "epoch number: 0, avg train accuracy: 0.42661448140900193, avg dev accuracy: 0.42727272727272725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:02,  2.61s/it]\n",
      "train: 0it [00:02, ?it/s]\n",
      "train eval: 1it [00:01,  1.35s/it]\n",
      "dev eval: 1it [00:00,  3.29it/s]\n",
      "train eval: 1it [00:01,  1.26s/it]\n",
      "dev eval: 1it [00:00,  3.32it/s]\n",
      "/opt/conda/envs/cs229/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:1013: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 1, para train accuracy: 0.649706457925636, para dev accuracy: 0.6363636363636364, sts train accuracy: 0.22113502935420742, sts dev accuracy: 0.22727272727272727\n",
      "epoch number: 1, avg train accuracy: 0.43542074363992167, avg dev accuracy: 0.4318181818181818\n",
      "New best model. Saving.\n",
      "saved the model to ./models/multitask_pcgrad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:02,  2.65s/it]\n",
      "train: 0it [00:02, ?it/s]\n",
      "train eval: 1it [00:01,  1.37s/it]\n",
      "dev eval: 1it [00:00,  3.22it/s]\n",
      "train eval: 1it [00:01,  1.28s/it]\n",
      "dev eval: 1it [00:00,  3.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 2, para train accuracy: 0.8082191780821918, para dev accuracy: 0.6909090909090909, sts train accuracy: 0.14481409001956946, sts dev accuracy: 0.18181818181818182\n",
      "epoch number: 2, avg train accuracy: 0.4765166340508806, avg dev accuracy: 0.4363636363636364\n",
      "New best model. Saving.\n",
      "saved the model to ./models/multitask_pcgrad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:02,  2.71s/it]\n",
      "train: 0it [00:02, ?it/s]\n",
      "train eval: 1it [00:01,  1.39s/it]\n",
      "dev eval: 1it [00:00,  3.18it/s]\n",
      "train eval: 1it [00:01,  1.28s/it]\n",
      "dev eval: 1it [00:00,  3.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 3, para train accuracy: 0.350293542074364, para dev accuracy: 0.36363636363636365, sts train accuracy: 0.14481409001956946, sts dev accuracy: 0.18181818181818182\n",
      "epoch number: 3, avg train accuracy: 0.24755381604696672, avg dev accuracy: 0.2727272727272727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:02,  2.67s/it]\n",
      "train: 0it [00:02, ?it/s]\n",
      "train eval: 1it [00:01,  1.39s/it]\n",
      "dev eval: 1it [00:00,  3.20it/s]\n",
      "train eval: 1it [00:01,  1.29s/it]\n",
      "dev eval: 1it [00:00,  3.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 4, para train accuracy: 0.4050880626223092, para dev accuracy: 0.36363636363636365, sts train accuracy: 0.14481409001956946, sts dev accuracy: 0.18181818181818182\n",
      "epoch number: 4, avg train accuracy: 0.2749510763209393, avg dev accuracy: 0.2727272727272727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:02,  2.68s/it]\n",
      "train: 0it [00:02, ?it/s]\n",
      "train eval: 1it [00:01,  1.39s/it]\n",
      "dev eval: 1it [00:00,  3.22it/s]\n",
      "train eval: 1it [00:01,  1.30s/it]\n",
      "dev eval: 1it [00:00,  3.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 5, para train accuracy: 0.7534246575342466, para dev accuracy: 0.6181818181818182, sts train accuracy: 0.14481409001956946, sts dev accuracy: 0.18181818181818182\n",
      "epoch number: 5, avg train accuracy: 0.449119373776908, avg dev accuracy: 0.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:02,  2.69s/it]\n",
      "train: 0it [00:02, ?it/s]\n",
      "train eval: 1it [00:01,  1.39s/it]\n",
      "dev eval: 1it [00:00,  3.17it/s]\n",
      "train eval: 1it [00:01,  1.30s/it]\n",
      "dev eval: 1it [00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 6, para train accuracy: 0.7553816046966731, para dev accuracy: 0.7, sts train accuracy: 0.14481409001956946, sts dev accuracy: 0.18181818181818182\n",
      "epoch number: 6, avg train accuracy: 0.4500978473581213, avg dev accuracy: 0.4409090909090909\n",
      "New best model. Saving.\n",
      "saved the model to ./models/multitask_pcgrad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1it [00:02,  2.74s/it]\n",
      "train: 0it [00:02, ?it/s]\n",
      "train eval: 1it [00:01,  1.39s/it]\n",
      "dev eval: 1it [00:00,  3.19it/s]\n",
      "train eval: 1it [00:01,  1.29s/it]\n",
      "dev eval: 1it [00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 7, para train accuracy: 0.735812133072407, para dev accuracy: 0.7090909090909091, sts train accuracy: 0.14481409001956946, sts dev accuracy: 0.18181818181818182\n",
      "epoch number: 7, avg train accuracy: 0.44031311154598823, avg dev accuracy: 0.44545454545454544\n",
      "New best model. Saving.\n",
      "saved the model to ./models/multitask_pcgrad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 0it [00:01, ?it/s]\n",
      "train: 0it [00:01, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m test_multitask_model(\u001b[39m'\u001b[39;49m\u001b[39m./models/multitask_pcgrad\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39mTrue\u001b[39;49;00m)\n",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m, in \u001b[0;36mtest_multitask_model\u001b[0;34m(filepath, pcgrad_flag)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtest_multitask_model\u001b[39m(filepath, pcgrad_flag):\n\u001b[0;32m----> 2\u001b[0m     train_multitask_model(para_train, para_dev, sts_train, sts_dev, filepath, pcgrad_flag)\n\u001b[1;32m      4\u001b[0m     device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m     model, _ \u001b[39m=\u001b[39m load_model(filepath, device)\n",
      "Cell \u001b[0;32mIn[22], line 44\u001b[0m, in \u001b[0;36mtrain_multitask_model\u001b[0;34m(para_train, para_dev, sts_train, sts_dev, filepath, pcgrad_flag)\u001b[0m\n\u001b[1;32m     41\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     43\u001b[0m para_logits \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mforward(b_para_sentences1, b_para_sentences2, \u001b[39m0\u001b[39m, device)\u001b[39m.\u001b[39mflatten()\n\u001b[0;32m---> 44\u001b[0m sts_logits \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mforward(b_sts_sentences1, b_sts_sentences2, \u001b[39m1\u001b[39;49m, device)\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m     46\u001b[0m b_para_labels \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mas_tensor(b_para_labels\u001b[39m.\u001b[39mvalues, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m     47\u001b[0m b_para_labels \u001b[39m=\u001b[39m b_para_labels\u001b[39m.\u001b[39mto(device)\n",
      "Cell \u001b[0;32mIn[17], line 27\u001b[0m, in \u001b[0;36mNLP_Model.forward\u001b[0;34m(self, sentences1, sentences2, task, device)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, sentences1, sentences2, task, device):\n\u001b[1;32m     24\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39m    Task 0 is para. Task 1 is similarity.\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     sentences1 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mas_tensor(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mencode(sentences1\u001b[39m.\u001b[39;49mtolist()))\n\u001b[1;32m     28\u001b[0m     sentences1 \u001b[39m=\u001b[39m sentences1\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     29\u001b[0m     sentences2 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mas_tensor(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mencode(sentences2\u001b[39m.\u001b[39mtolist()))\n",
      "File \u001b[0;32m/opt/conda/envs/cs229/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:188\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[39m# fixes for #522 and #487 to avoid oom problems on gpu with large datasets\u001b[39;00m\n\u001b[1;32m    187\u001b[0m             \u001b[39mif\u001b[39;00m convert_to_numpy:\n\u001b[0;32m--> 188\u001b[0m                 embeddings \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39;49mcpu()\n\u001b[1;32m    190\u001b[0m         all_embeddings\u001b[39m.\u001b[39mextend(embeddings)\n\u001b[1;32m    192\u001b[0m all_embeddings \u001b[39m=\u001b[39m [all_embeddings[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39margsort(length_sorted_idx)]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_multitask_model('./models/multitask_pcgrad', True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
