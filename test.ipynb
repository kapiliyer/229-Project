{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from random import sample\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "for folder in ['multitask', 'para_single', 'sts_single', 'multitask_pcgrad', 'multitask_gradnorm', 'multitask_cagrad']:\n",
    "    try:\n",
    "        os.mkdir('./models/' + folder)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "sts_train = pd.read_csv('./data/sts-train.csv', sep=\"\\t\")\n",
    "sts_train = sts_train.dropna()\n",
    "\n",
    "para_train = pd.read_csv('./data/quora-train.csv', sep=\"\\t\")\n",
    "para_train = para_train.dropna()[:len(sts_train)]\n",
    "\n",
    "sts_dev = pd.read_csv('./data/sts-dev.csv', sep=\"\\t\")\n",
    "sts_dev = sts_dev.dropna() \n",
    "\n",
    "para_dev = pd.read_csv('./data/quora-dev.csv', sep=\"\\t\")\n",
    "para_dev = para_dev.dropna()[:len(sts_dev)]\n",
    "\n",
    "sts_combined_set = pd.concat([sts_train, sts_dev], ignore_index=True, axis=0)\n",
    "para_combined_set = pd.concat([para_train, para_dev], ignore_index=True, axis=0)\n",
    "\n",
    "sts_train, sts_dev = train_test_split(sts_combined_set, test_size=0.3, train_size=0.7, shuffle=False)\n",
    "sts_dev, sts_test = train_test_split(sts_dev, test_size=0.5, train_size=0.5, shuffle=False)\n",
    "para_train, para_dev = train_test_split(para_combined_set, test_size=0.3, train_size=0.7, shuffle=False)\n",
    "para_dev, para_test = train_test_split(para_dev, test_size=0.5, train_size=0.5, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cs229/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "# sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "# model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "# embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "# print(embeddings)\n",
    "# print(para_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "N_PARAPHRASE_CLASSES = 1\n",
    "N_SIMILARITY_CLASSES = 1\n",
    "DROPOUT_PROB = 0.5\n",
    "INPUT_SIZE = 768\n",
    "\n",
    "class NLP_Model(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(NLP_Model, self).__init__()\n",
    "        self.model = model\n",
    "        self.dropout = nn.Dropout(DROPOUT_PROB)\n",
    "        self.paraphrase_linear = nn.Linear(INPUT_SIZE, INPUT_SIZE // 2)\n",
    "        self.paraphrase_linear_interact = nn.Linear(INPUT_SIZE, N_PARAPHRASE_CLASSES)\n",
    "        self.similarity_linear = nn.Linear(INPUT_SIZE, INPUT_SIZE // 2)\n",
    "    \n",
    "    def forward(self, sentences1, sentences2, task, device):\n",
    "        '''\n",
    "        Task 0 is para. Task 1 is similarity.\n",
    "        '''\n",
    "        sentences1 = self.model.encode(sentences1.tolist(), convert_to_tensor=True)\n",
    "        sentences1 = sentences1.to(device)\n",
    "        sentences2 = self.model.encode(sentences2.tolist(), convert_to_tensor=True)\n",
    "        sentences2 = sentences2.to(device)\n",
    "        sentences1 = self.dropout(sentences1)\n",
    "        sentences2 = self.dropout(sentences2)\n",
    "        if task == 0:\n",
    "            sentences1 = F.relu(self.paraphrase_linear(sentences1))\n",
    "            sentences2 = F.relu(self.paraphrase_linear(sentences2))\n",
    "            combined = torch.concat((sentences1, sentences2), dim=-1)\n",
    "            combined = self.dropout(combined)\n",
    "            return F.sigmoid(self.paraphrase_linear_interact(combined))\n",
    "        if task == 1:\n",
    "            sentences1 = F.relu(self.similarity_linear(sentences1))\n",
    "            sentences2 = F.relu(self.similarity_linear(sentences2))\n",
    "            return F.relu(F.cosine_similarity(sentences1, sentences2)) * 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "def save_model(model, filepath):\n",
    "    save_info = {\n",
    "        'model': model.state_dict(),\n",
    "        'system_rng': random.getstate(),\n",
    "        'numpy_rng': np.random.get_state(),\n",
    "        'torch_rng': torch.random.get_rng_state(),\n",
    "    }\n",
    "\n",
    "    torch.save(save_info, f'{filepath}/model')\n",
    "    model.model.save(f'{filepath}/transformer')\n",
    "    print(f\"saved the model to {filepath}\")\n",
    "\n",
    "def load_model(filepath, device):\n",
    "    with torch.no_grad():\n",
    "        save_info = torch.load(f'{filepath}/model')\n",
    "        transformer_model = SentenceTransformer(f'{filepath}/transformer')\n",
    "        transformer_model.to(device)\n",
    "        \n",
    "        model = NLP_Model(transformer_model)\n",
    "        model.load_state_dict(save_info['model'])\n",
    "        model.to(device)\n",
    "        \n",
    "        random.setstate(save_info['system_rng'])\n",
    "        np.random.set_state(save_info['numpy_rng'])\n",
    "        torch.random.set_rng_state(save_info['torch_rng'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "def get_batches(dataset, batch_size=512):\n",
    "    \"\"\"\n",
    "    Pass in dataset and batch size.\n",
    "    Get generator which yields batches.\n",
    "    \"\"\"\n",
    "    return enumerate(dataset[i*batch_size:(i+1)*batch_size] for i in range(ceil(dataset.shape[0] / batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "NUM_EPOCHS = 30\n",
    "\n",
    "def train_singletask_para_model(para_train, para_dev, filepath):\n",
    "    '''\n",
    "    use AdamW optimizer.\n",
    "    binary cross-entropy loss.\n",
    "    make sure to save model at end to a specific path.\n",
    "    '''\n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "    transformer = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "    transformer.to(device)\n",
    "\n",
    "    model = NLP_Model(transformer)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = AdamW(list(model.parameters()) + list(transformer.parameters()), lr=1e-2) #~SGD with weight decay 0.01\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'max')\n",
    "\n",
    "    best_dev_acc = 0\n",
    "\n",
    "    train_para_accuracy = eval_singletask_model(model, device, para_train, 0, 'train')\n",
    "    dev_para_accuracy = eval_singletask_model(model, device, para_dev, 0, 'dev')\n",
    "    print(f\"epoch number: 0, para train accuracy: {train_para_accuracy}, para dev accuracy: {dev_para_accuracy}\")\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        transformer.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for step, batch in tqdm(get_batches(para_train), desc='train'):\n",
    "            b_sentences1, b_sentences2, b_labels = batch['sentence1'], batch['sentence2'], batch['is_duplicate']\n",
    "            optimizer.zero_grad()\n",
    "            logits = model.forward(b_sentences1, b_sentences2, 0, device).flatten()\n",
    "\n",
    "            b_labels = torch.as_tensor(b_labels.values, dtype=torch.float32)\n",
    "            b_labels = b_labels.to(device)\n",
    "\n",
    "            loss = F.binary_cross_entropy(logits, b_labels, reduction='mean')\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        losses.append(total_loss / step)\n",
    "        \n",
    "        train_para_accuracy = eval_singletask_model(model, device, para_train, 0, 'train')\n",
    "        dev_para_accuracy = eval_singletask_model(model, device, para_dev, 0, 'dev')\n",
    "        print(f\"epoch number: {epoch + 1}, para train accuracy: {train_para_accuracy}, para dev accuracy: {dev_para_accuracy}\")\n",
    "\n",
    "        scheduler.step(dev_para_accuracy)\n",
    "\n",
    "        if dev_para_accuracy >= best_dev_acc:\n",
    "            best_dev_acc = dev_para_accuracy\n",
    "            print('New best model. Saving.')\n",
    "            save_model(model, filepath)\n",
    "    \n",
    "    print(losses)\n",
    "\n",
    "\n",
    "def train_singletask_sts_model(sts_train, sts_dev, filepath):\n",
    "    '''\n",
    "    use AdamW optimizer.\n",
    "    multi-class cross-entropy loss.\n",
    "    make sure to save model at end to a specific path.\n",
    "    '''\n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "    transformer = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "    transformer.to(device)\n",
    "\n",
    "    model = NLP_Model(transformer)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = AdamW(list(model.parameters()) + list(transformer.parameters()), lr=1e-2) #~SGD with weight decay 0.01\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'max')\n",
    "\n",
    "    best_dev_acc = 0\n",
    "\n",
    "    train_sts_acc = eval_singletask_model(model, device, sts_train, 1, 'train')\n",
    "    dev_sts_acc = eval_singletask_model(model, device, sts_dev, 1, 'dev')\n",
    "    print(f\"epoch number: 0, sts train accuracy: {train_sts_acc}, sts dev accuracy: {dev_sts_acc}\")\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        transformer.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for step, batch in tqdm(get_batches(sts_train), desc='train'):\n",
    "            b_sentences1, b_sentences2, b_labels = batch['sentence1'], batch['sentence2'], batch['similarity']\n",
    "            optimizer.zero_grad()\n",
    "            logits = model.forward(b_sentences1, b_sentences2, 1, device).flatten()\n",
    "\n",
    "            b_labels = torch.as_tensor(b_labels.values, dtype=torch.float32)\n",
    "            b_labels = b_labels.to(device)\n",
    "\n",
    "            loss = F.mse_loss(logits, b_labels, reduction='mean')\n",
    "            total_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        losses.append(total_loss / step)\n",
    "\n",
    "        train_sts_acc = eval_singletask_model(model, device, sts_train, 1, 'train')\n",
    "        dev_sts_acc = eval_singletask_model(model, device, sts_dev, 1, 'dev')\n",
    "        print(f\"epoch number: {epoch + 1}, sts train accuracy: {train_sts_acc}, sts dev accuracy: {dev_sts_acc}\")\n",
    "\n",
    "        scheduler.step(dev_sts_acc)\n",
    "\n",
    "        if dev_sts_acc >= best_dev_acc:\n",
    "            best_dev_acc = dev_sts_acc\n",
    "            print('New best model. Saving.')\n",
    "            save_model(model, filepath)\n",
    "    \n",
    "    print(losses)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/docs/transformers/training#train-in-native-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_singletask_model(model, device, dataset, task, flag):\n",
    "    '''\n",
    "    given dataloader, 2 task-specific finetuned models, and device\n",
    "    return the accuracy for para and for sts\n",
    "    '''\n",
    "    model.eval()\n",
    "    model.model.eval()\n",
    "    with torch.no_grad():\n",
    "        truth = []\n",
    "        predictions = []\n",
    "        for step, batch in tqdm(get_batches(dataset), desc=f\"{flag} eval\"):\n",
    "            b_sentences1, b_sentences2, b_labels = batch['sentence1'], batch['sentence2'], batch['is_duplicate' if task == 0 else 'similarity']\n",
    "            truth.extend(b_labels)\n",
    "            logits = model.forward(b_sentences1, b_sentences2, task, device)\n",
    "            logits = logits.detach().cpu().numpy().flatten()\n",
    "            if task == 0:\n",
    "                new_predictions = np.round(logits).flatten()\n",
    "            else:\n",
    "                new_predictions = logits.flatten()\n",
    "            predictions.extend(new_predictions)\n",
    "        if task == 0:\n",
    "            accuracy = (np.array(truth).flatten() == np.array(predictions).flatten()).mean()\n",
    "        else:\n",
    "            accuracy = (np.abs(np.array(truth).flatten() - np.array(predictions).flatten()) <= 0.5).mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcgrad import PCGrad\n",
    "\n",
    "def train_multitask_model(para_train, para_dev, sts_train, sts_dev, filepath, pcgrad_flag):\n",
    "    '''\n",
    "    use AdamW optimizer.\n",
    "    binary cross-entropy loss for para, multi-class cross-entropy loss for sts, sum loss functions. \n",
    "    make sure to save model at end to a specific path.\n",
    "    '''\n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "    transformer = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "    transformer.to(device)\n",
    "\n",
    "    model = NLP_Model(transformer)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = AdamW(list(model.parameters()) + list(transformer.parameters()), lr=1e-2) #~SGD with weight decay 0.01\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "    if pcgrad_flag: optimizer = PCGrad(optimizer)\n",
    "\n",
    "    best_dev_acc = 0\n",
    "\n",
    "    train_para_acc = eval_singletask_model(model, device, para_train, 0, 'train')\n",
    "    dev_para_acc = eval_singletask_model(model, device, para_dev, 0, 'dev')\n",
    "    train_sts_acc = eval_singletask_model(model, device, sts_train, 1, 'train')\n",
    "    dev_sts_acc = eval_singletask_model(model, device, sts_dev, 1, 'dev')\n",
    "    print(f\"epoch number: 0, para train accuracy: {train_para_acc}, para dev accuracy: {dev_para_acc}, sts train accuracy: {train_sts_acc}, sts dev accuracy: {dev_sts_acc}\")\n",
    "\n",
    "    train_acc = (train_para_acc + train_sts_acc) / 2\n",
    "    dev_acc = (dev_para_acc + dev_sts_acc) / 2\n",
    "    print(f\"epoch number: 0, avg train accuracy: {train_acc}, avg dev accuracy: {dev_acc}\")\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        transformer.train()\n",
    "\n",
    "        for (para_step, para_batch), (sts_step, sts_batch) in zip(tqdm(get_batches(para_train), desc='train'), tqdm(get_batches(sts_train), desc='train')):\n",
    "            b_para_sentences1, b_para_sentences2, b_para_labels = para_batch['sentence1'], para_batch['sentence2'], para_batch['is_duplicate']\n",
    "            b_sts_sentences1, b_sts_sentences2, b_sts_labels = sts_batch['sentence1'], sts_batch['sentence2'], sts_batch['similarity']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            para_logits = model.forward(b_para_sentences1, b_para_sentences2, 0, device).flatten()\n",
    "            sts_logits = model.forward(b_sts_sentences1, b_sts_sentences2, 1, device).flatten()\n",
    "\n",
    "            b_para_labels = torch.as_tensor(b_para_labels.values, dtype=torch.float32)\n",
    "            b_para_labels = b_para_labels.to(device)\n",
    "            b_sts_labels = torch.as_tensor(b_sts_labels.values, dtype=torch.float32)\n",
    "            b_sts_labels = b_sts_labels.to(device)\n",
    "\n",
    "            loss = (F.binary_cross_entropy(para_logits, b_para_labels, reduction='mean') + F.mse_loss(sts_logits, b_sts_labels, reduction='mean')) / 2\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_para_acc = eval_singletask_model(model, device, para_train, 0, 'train')\n",
    "        dev_para_acc = eval_singletask_model(model, device, para_dev, 0, 'dev')\n",
    "        train_sts_acc = eval_singletask_model(model, device, sts_train, 1, 'train')\n",
    "        dev_sts_acc = eval_singletask_model(model, device, sts_dev, 1, 'dev')\n",
    "        print(f\"epoch number: {epoch + 1}, para train accuracy: {train_para_acc}, para dev accuracy: {dev_para_acc}, sts train accuracy: {train_sts_acc}, sts dev accuracy: {dev_sts_acc}\")\n",
    "\n",
    "        train_acc = (train_para_acc + train_sts_acc) / 2\n",
    "        dev_acc = (dev_para_acc + dev_sts_acc) / 2\n",
    "        print(f\"epoch number: {epoch + 1}, avg train accuracy: {train_acc}, avg dev accuracy: {dev_acc}\")\n",
    "\n",
    "        scheduler.step(dev_acc, 'max')\n",
    "\n",
    "        if dev_acc >= best_dev_acc:\n",
    "            best_dev_acc = dev_acc\n",
    "            print('New best model. Saving.')\n",
    "            save_model(model, filepath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cagrad import *\n",
    "\n",
    "def train_multitask_model_cagrad(para_train, para_dev, sts_train, sts_dev, filepath):\n",
    "    '''\n",
    "    use AdamW optimizer.\n",
    "    binary cross-entropy loss for para, multi-class cross-entropy loss for sts, sum loss functions. \n",
    "    make sure to save model at end to a specific path.\n",
    "    '''\n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "    transformer = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "    transformer.to(device)\n",
    "\n",
    "    model = NLP_Model(transformer)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = AdamW(list(model.parameters()) + list(transformer.parameters()), lr=1e-2) #~SGD with weight decay 0.01\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "\n",
    "    best_dev_acc = 0\n",
    "\n",
    "    train_para_acc = eval_singletask_model(model, device, para_train, 0, 'train')\n",
    "    dev_para_acc = eval_singletask_model(model, device, para_dev, 0, 'dev')\n",
    "    train_sts_acc = eval_singletask_model(model, device, sts_train, 1, 'train')\n",
    "    dev_sts_acc = eval_singletask_model(model, device, sts_dev, 1, 'dev')\n",
    "    print(f\"epoch number: 0, para train accuracy: {train_para_acc}, para dev accuracy: {dev_para_acc}, sts train accuracy: {train_sts_acc}, sts dev accuracy: {dev_sts_acc}\")\n",
    "\n",
    "    train_acc = (train_para_acc + train_sts_acc) / 2\n",
    "    dev_acc = (dev_para_acc + dev_sts_acc) / 2\n",
    "    print(f\"epoch number: 0, avg train accuracy: {train_acc}, avg dev accuracy: {dev_acc}\")\n",
    "    \n",
    "    linear_params = get_linear_params(model)\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        transformer.train()\n",
    "\n",
    "        for (para_step, para_batch), (sts_step, sts_batch) in zip(tqdm(get_batches(para_train), desc='train'), tqdm(get_batches(sts_train), desc='train')):\n",
    "            b_para_sentences1, b_para_sentences2, b_para_labels = para_batch['sentence1'], para_batch['sentence2'], para_batch['is_duplicate']\n",
    "            b_sts_sentences1, b_sts_sentences2, b_sts_labels = sts_batch['sentence1'], sts_batch['sentence2'], sts_batch['similarity']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            para_logits = model.forward(b_para_sentences1, b_para_sentences2, 0, device).flatten()\n",
    "            sts_logits = model.forward(b_sts_sentences1, b_sts_sentences2, 1, device).flatten()\n",
    "\n",
    "            b_para_labels = torch.as_tensor(b_para_labels.values, dtype=torch.float32)\n",
    "            b_para_labels = b_para_labels.to(device)\n",
    "            b_sts_labels = torch.as_tensor(b_sts_labels.values, dtype=torch.float32)\n",
    "            b_sts_labels = b_sts_labels.to(device)\n",
    "            \n",
    "            loss1 = F.binary_cross_entropy(para_logits, b_para_labels, reduction='mean')\n",
    "            loss1.backward()\n",
    "            para_grad = get_1d_grads(linear_params)\n",
    "            \n",
    "            loss2 = F.mse_loss(sts_logits, b_sts_labels, reduction='mean')\n",
    "            loss2.backward()\n",
    "            sts_grad = get_1d_grads(linear_params)\n",
    "            \n",
    "            new_grad = cagrad(para_grad, sts_grad)\n",
    "            apply_1d_grad(new_grad, linear_params)\n",
    "            optimizer.step()\n",
    "\n",
    "        train_para_acc = eval_singletask_model(model, device, para_train, 0, 'train')\n",
    "        dev_para_acc = eval_singletask_model(model, device, para_dev, 0, 'dev')\n",
    "        train_sts_acc = eval_singletask_model(model, device, sts_train, 1, 'train')\n",
    "        dev_sts_acc = eval_singletask_model(model, device, sts_dev, 1, 'dev')\n",
    "        print(f\"epoch number: {epoch + 1}, para train accuracy: {train_para_acc}, para dev accuracy: {dev_para_acc}, sts train accuracy: {train_sts_acc}, sts dev accuracy: {dev_sts_acc}\")\n",
    "\n",
    "        train_acc = (train_para_acc + train_sts_acc) / 2\n",
    "        dev_acc = (dev_para_acc + dev_sts_acc) / 2\n",
    "        print(f\"epoch number: {epoch + 1}, avg train accuracy: {train_acc}, avg dev accuracy: {dev_acc}\")\n",
    "\n",
    "        scheduler.step(dev_acc, 'max')\n",
    "\n",
    "        if dev_acc >= best_dev_acc:\n",
    "            best_dev_acc = dev_acc\n",
    "            print('New best model. Saving.')\n",
    "            save_model(model, filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_multitask_model_gradnorm(para_train, para_dev, sts_train, sts_dev, filepath, alpha, layer):\n",
    "    '''\n",
    "    use AdamW optimizer.\n",
    "    binary cross-entropy loss for para, multi-class cross-entropy loss for sts, sum loss functions. \n",
    "    make sure to save model at end to a specific path.\n",
    "    '''\n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "    transformer = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "    transformer.to(device)\n",
    "\n",
    "    model = NLP_Model(transformer)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = AdamW(list(model.parameters()) + list(transformer.parameters()), lr=1e-2) #~SGD with weight decay 0.01\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "\n",
    "    best_dev_acc = 0\n",
    "\n",
    "    train_para_acc = eval_singletask_model(model, device, para_train, 0, 'train')\n",
    "    dev_para_acc = eval_singletask_model(model, device, para_dev, 0, 'dev')\n",
    "    train_sts_acc = eval_singletask_model(model, device, sts_train, 1, 'train')\n",
    "    dev_sts_acc = eval_singletask_model(model, device, sts_dev, 1, 'dev')\n",
    "    print(f\"epoch number: 0, para train accuracy: {train_para_acc}, para dev accuracy: {dev_para_acc}, sts train accuracy: {train_sts_acc}, sts dev accuracy: {dev_sts_acc}\")\n",
    "\n",
    "    train_acc = (train_para_acc + train_sts_acc) / 2\n",
    "    dev_acc = (dev_para_acc + dev_sts_acc) / 2\n",
    "    print(f\"epoch number: 0, avg train accuracy: {train_acc}, avg dev accuracy: {dev_acc}\")\n",
    "\n",
    "    iters = 0\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        transformer.train()\n",
    "\n",
    "        for (para_step, para_batch), (sts_step, sts_batch) in zip(tqdm(get_batches(para_train), desc='train'), tqdm(get_batches(sts_train), desc='train')):\n",
    "            b_para_sentences1, b_para_sentences2, b_para_labels = para_batch['sentence1'], para_batch['sentence2'], para_batch['is_duplicate']\n",
    "            b_sts_sentences1, b_sts_sentences2, b_sts_labels = sts_batch['sentence1'], sts_batch['sentence2'], sts_batch['similarity']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            para_logits = model.forward(b_para_sentences1, b_para_sentences2, 0, device).flatten()\n",
    "            sts_logits = model.forward(b_sts_sentences1, b_sts_sentences2, 1, device).flatten()\n",
    "\n",
    "            b_para_labels = torch.as_tensor(b_para_labels.values, dtype=torch.float32)\n",
    "            b_para_labels = b_para_labels.to(device)\n",
    "            b_sts_labels = torch.as_tensor(b_sts_labels.values, dtype=torch.float32)\n",
    "            b_sts_labels = b_sts_labels.to(device)\n",
    "\n",
    "            loss = (F.binary_cross_entropy(para_logits, b_para_labels, reduction='mean') + F.mse_loss(sts_logits, b_sts_labels, reduction='mean')) / 2\n",
    "            if iters == 0:\n",
    "                weights = torch.ones_like(loss)\n",
    "                weights = torch.nn.Parameter(weights)\n",
    "                T = weights.sum().detach()\n",
    "                optimizer2 = torch.optim.Adam([weights], lr=1e-2)\n",
    "                l0 = loss.detach()\n",
    "            weighted_loss = np.dot(weights, loss)\n",
    "            weighted_loss.backward()\n",
    "            gradient_weights = []\n",
    "            for i in range(len(loss)):\n",
    "                d_l = torch.autograd.grad(weights[i] * loss[i], layer.parameters())[0]\n",
    "                gradient_weights.append(torch.norm(d_l))\n",
    "            gradient_weights = torch.stack(gradient_weights)\n",
    "            lossratio = loss.detach() / l0\n",
    "            r_t = lossratio / lossratio.mean()\n",
    "            avg_gradient_weight = gradient_weights.mean().detach()\n",
    "            const_factor = (avg_gradient_weight * r_t ** alpha).detach()\n",
    "            gradnormloss = torch.abs(gradient_weights - const_factor).sum()\n",
    "            optimizer2.zero_grad()\n",
    "            gradnormloss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer2.step()\n",
    "            weights = (weights / weights.sum() * T).detach()\n",
    "            weights = torch.nn.Parameter(weights)\n",
    "            optimizer2 = torch.optim.Adam([weights], lr=1e-2)\n",
    "            iters += 1\n",
    "\n",
    "        train_para_acc = eval_singletask_model(model, device, para_train, 0, 'train')\n",
    "        dev_para_acc = eval_singletask_model(model, device, para_dev, 0, 'dev')\n",
    "        train_sts_acc = eval_singletask_model(model, device, sts_train, 1, 'train')\n",
    "        dev_sts_acc = eval_singletask_model(model, device, sts_dev, 1, 'dev')\n",
    "        print(f\"epoch number: {epoch + 1}, para train accuracy: {train_para_acc}, para dev accuracy: {dev_para_acc}, sts train accuracy: {train_sts_acc}, sts dev accuracy: {dev_sts_acc}\")\n",
    "\n",
    "        train_acc = (train_para_acc + train_sts_acc) / 2\n",
    "        dev_acc = (dev_para_acc + dev_sts_acc) / 2\n",
    "        print(f\"epoch number: {epoch + 1}, avg train accuracy: {train_acc}, avg dev accuracy: {dev_acc}\")\n",
    "\n",
    "        scheduler.step(dev_acc, 'max')\n",
    "\n",
    "        if dev_acc >= best_dev_acc:\n",
    "            best_dev_acc = dev_acc\n",
    "            print('New best model. Saving.')\n",
    "            save_model(model, filepath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_singletask_model(filepath1, filepath2):\n",
    "    train_singletask_para_model(para_train, para_dev, filepath1)\n",
    "    train_singletask_sts_model(sts_train, sts_dev, filepath2)\n",
    "\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "    para_model = load_model(filepath1, device)\n",
    "    sts_model = load_model(filepath2, device)\n",
    "\n",
    "    para_acc = eval_singletask_model(para_model, device, para_test, 0, 'test')\n",
    "    sts_acc = eval_singletask_model(sts_model, device, sts_test, 1, 'test')\n",
    "\n",
    "    print(f'Final test accuracy. PARA: {para_acc}, STS: {sts_acc}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_singletask_model('./models/para_single', './models/sts_single')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_multitask_model(filepath, pcgrad_flag):\n",
    "    train_multitask_model(para_train, para_dev, sts_train, sts_dev, filepath, pcgrad_flag)\n",
    "\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "    model = load_model(filepath, device)\n",
    "\n",
    "    para_acc = eval_singletask_model(model, device, para_test, 0, 'test')\n",
    "    sts_acc = eval_singletask_model(model, device, sts_test, 1, 'test')\n",
    "\n",
    "    print(f'Final test accuracy. PARA: {para_acc}, STS: {sts_acc}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_multitask_model('./models/multitask', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_multitask_model('./models/multitask_pcgrad', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss(sts_loss, para_loss, title, filename=None):\n",
    "    plt.plot(sts_loss, label='STS loss')\n",
    "    plt.plot(para_loss, label='Para loss')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('# Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    if filename is not None:\n",
    "        plt.savefig(filename, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAHHCAYAAABdm0mZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABcsUlEQVR4nO3dd3wUdf7H8dduyqYXSIeQUKRDKEJElKIooGI/sZygnh0r6k+woZ6K5UROsd95nh1FxYZHU+BQlKOEJiA9oaQB6aTtzu+PJQtrAmzCJpPyfj4e88ju7MzuJ+Nq3s63WQzDMBARERFpZqxmFyAiIiJSHxRyREREpFlSyBEREZFmSSFHREREmiWFHBEREWmWFHJERESkWVLIERERkWZJIUdERESaJYUcERERaZYUckTEVI8//jgWi8WjY999910sFgs7d+6s36L+oKrG3NzcBv3ck2WxWHj88cdrfd7OnTuxWCy8++67Xq9JpCEp5IiYrOoPd0BAAHv27Kn2+rBhw+jZs6cJlR2pzWKxsHTp0mqvG4ZBYmIiFouFCy64wGuf+8wzzzB79myPjn3ttdca9R9js66hiCjkiDQaZWVlPPvss2aXUaOAgAA++uijavsXL17M7t27sdlsXv28Y4Wca6+9lkOHDpGUlOTa19hDTpWGvoYiopAj0mj06dOHt99+m71795pdSjXnnXcen332GZWVlW77P/roI/r3709cXFyD1OHj40NAQIDHzVuNSWO5hiItiUKOSCPx0EMPYbfbPbqbU1lZyV//+lc6duyIzWYjOTmZhx56iLKyMrfjkpOTueCCC1i6dCkDBw4kICCADh068N5779Wqtquuuor9+/czf/58177y8nJmzZrF1VdfXe34RYsWYbFYWLRokdt+T/p6WCwWiouL+fe//+1q5rnuuuuA6n1ykpOT2bBhA4sXL3YdO2zYMAAOHDjA/fffT69evQgJCSEsLIzRo0ezZs2aap/5yiuv0KNHD4KCgoiMjOTUU0+t8a7L0Xbt2kWnTp3o2bMnWVlZxz0Wan8NAYqLi7nvvvtITEzEZrPRpUsX/va3v2EYhttxZWVl3HvvvURHRxMaGsqFF17I7t27a3zPPXv2cMMNNxAbG4vNZqNHjx688847J6xfpClSyBFpJNq3b8+4ceM8uptz44038thjj9GvXz9eeuklhg4dytSpU7nyyiurHbt161Yuv/xyzjnnHF588UUiIyO57rrr2LBhg8e1JScnM2jQID7++GPXvu+//578/PwaP/NkvP/++9hsNs4880zef/993n//fW655ZYaj50+fTpt27ala9eurmMffvhhALZv387s2bO54IILmDZtGg888ADr1q1j6NChbtf37bff5q677qJ79+5Mnz6dJ554gj59+vDrr78es8Zt27YxZMgQQkNDWbRoEbGxsSf8vWp7DQ3D4MILL+Sll15i1KhRTJs2jS5duvDAAw8wceJEt2NvvPFGpk+fzrnnnsuzzz6Ln58f559/frX3zMrK4rTTTmPBggXccccd/P3vf6dTp0785S9/Yfr06Sf8HUSaHENETPWvf/3LAIz//e9/xrZt2wxfX1/jrrvucr0+dOhQo0ePHq7naWlpBmDceOONbu9z//33G4Dxww8/uPYlJSUZgLFkyRLXvuzsbMNmsxn33XdfrWqbMWOGERoaapSUlBiGYRh/+tOfjOHDh7s+5/zzz3ed9+OPPxqA8eOPP7q9344dOwzA+Ne//uXaN2XKFOOP/ykKDg42xo8ff8x6duzY4drXo0cPY+jQodWOLS0tNex2e7XPt9lsxpNPPunad9FFF7ld35pU1ZiTk2Ns3LjRSEhIMAYMGGAcOHDguOcdXXNtr+Hs2bMNwHjqqafc3u/yyy83LBaLsXXrVsMwjnwfbr/9drfjrr76agMwpkyZ4tr3l7/8xYiPjzdyc3Pdjr3yyiuN8PBwV101/XMSaYp0J0ekEenQoQPXXnstb731Fvv27avxmDlz5gBU+7/5++67D4DvvvvObX/37t0588wzXc+jo6Pp0qUL27dvr1VtV1xxBYcOHeLbb7+lsLCQb7/99pjNLI2BzWbDanX+J85ut7N//35CQkLo0qULq1atch0XERHB7t27+d///nfC91y/fj1Dhw4lOTmZBQsWEBkZWauaanMN58yZg4+PD3fddZfb/vvuuw/DMPj+++9dxwHVjrvnnnvcnhuGweeff86YMWMwDIPc3FzXNnLkSPLz892ui0hzoJAj0sg88sgjVFZWHrNvzq5du7BarXTq1Mltf1xcHBEREezatcttf7t27aq9R2RkJAcPHgScASAzM9NtKy8vr3ZOdHQ0I0aM4KOPPuKLL77Abrdz+eWX1/XXrHcOh4OXXnqJU045BZvNRlRUFNHR0axdu5b8/HzXcQ8++CAhISEMHDiQU045hQkTJvDTTz/V+J5jxowhNDSUuXPnEhYWVuuaanMNd+3aRUJCAqGhoW77u3Xr5nq96qfVaqVjx45ux3Xp0sXteU5ODnl5ebz11ltER0e7bddffz0A2dnZtf6dRBozhRyRRqZDhw78+c9/Pu7dHMDjEUY+Pj417jcOd17NyMggPj7ebfv5559rPOfqq6/m+++/54033mD06NFERETUqja73e5Rzd7wzDPPMHHiRIYMGcIHH3zA3LlzmT9/Pj169MDhcLiO69atG5s3b+aTTz7hjDPO4PPPP+eMM85gypQp1d7zsssuY9u2bXz44Yd1rsvTa+htVb/zn//8Z+bPn1/jNnjw4AapRaSh+JpdgIhU98gjj/DBBx/w3HPPVXstKSkJh8PBli1bXP9XD85OpXl5eW5zyHgiLi7ObcQPQEpKSo3HXnLJJdxyyy388ssvzJw585jvWdWMk5eX57b/j3eZjqU2Q8SPdeysWbMYPnw4//znP9325+XlERUV5bYvODiYsWPHMnbsWMrLy7n00kt5+umnmTx5MgEBAa7jXnjhBXx9fbn99tsJDQ2tU3Odp9cwKSmJBQsWUFhY6HY3Z9OmTa7Xq346HA62bdvmdvdm8+bNbu9XNfLKbrczYsSIWtct0hTpTo5II9SxY0f+/Oc/8+abb5KZmen22nnnnQdQbTTMtGnTAGocVXM8AQEBjBgxwm07Vl+TkJAQXn/9dR5//HHGjBlzzPdMSkrCx8eHJUuWuO1/7bXXPKopODi4WkCq7bE+Pj7Vhlp/9tln1WaV3r9/v9tzf39/unfvjmEYVFRUuL1msVh46623uPzyyxk/fjxff/21RzUezdNreN5552G325kxY4bb/pdeegmLxcLo0aMBXD9ffvllt+P++P3w8fHhsssu4/PPP2f9+vXVPi8nJ6fWv4tIY6c7OSKN1MMPP8z777/P5s2b6dGjh2t/SkoK48eP56233iIvL4+hQ4eyfPly/v3vf3PxxRczfPjweq1r/PjxJzwmPDycP/3pT7zyyitYLBY6duzIt99+63Gfj/79+7NgwQKmTZtGQkIC7du3JzU19ZjHvv766zz11FN06tSJmJgYzjrrLC644AKefPJJrr/+ek4//XTWrVvHhx9+SIcOHdzOP/fcc4mLi2Pw4MHExsayceNGZsyYwfnnn1+tPwyA1Wrlgw8+4OKLL+aKK65gzpw5nHXWWR79XlU8uYZjxoxh+PDhPPzww+zcuZOUlBTmzZvHV199xT333OPqg9OnTx+uuuoqXnvtNfLz8zn99NNZuHAhW7durfaezz77LD/++COpqancdNNNdO/enQMHDrBq1SoWLFjAgQMHavV7iDR6Zg7tEhH3IcZ/NH78eAOoNsS5oqLCeOKJJ4z27dsbfn5+RmJiojF58mSjtLTU7bg/DkuuMnTo0BqHXdemthN9Tk5OjnHZZZcZQUFBRmRkpHHLLbcY69ev92gI+aZNm4whQ4YYgYGBBuAaTl7TEPLMzEzj/PPPN0JDQw3A9XuVlpYa9913nxEfH28EBgYagwcPNpYtW1btd3/zzTeNIUOGGK1btzZsNpvRsWNH44EHHjDy8/Or1ZiTk+PaV1JSYgwdOtQICQkxfvnll3q5hoWFhca9995rJCQkGH5+fsYpp5xivPDCC4bD4XA77tChQ8Zdd91ltG7d2ggODjbGjBljZGRkVBtCbhiGkZWVZUyYMMFITEw0/Pz8jLi4OOPss8823nrrLdcxGkIuzYXFMP5wP1dERESkGVCfHBEREWmWFHJERESkWVLIERERkWZJIUdERESaJYUcERERaZYUckRERKRZanGTATocDvbu3UtoaGitpo4XERER8xiGQWFhIQkJCVitnt2jaXEhZ+/evSQmJppdhoiIiNRBRkYGbdu29ehYU0POkiVLeOGFF1i5ciX79u3jyy+/5OKLL/bo3J9++omhQ4fSs2dP0tLSPP7MqmnaMzIyCAsLq0PVIiIi0tAKCgpITEyscbmVYzE15BQXF5OSksINN9zApZde6vF5eXl5jBs3jrPPPpusrKxafWZVE1VYWJhCjoiISBNTm64mpoac0aNHu1bQrY1bb72Vq6++Gh8fH2bPnu39wkRERKTJa3Kjq/71r3+xfft2pkyZ4tHxZWVlFBQUuG0iIiLS/DWpkLNlyxYmTZrEBx98gK+vZzehpk6dSnh4uGtTp2MREZGWocmEHLvdztVXX80TTzxB586dPT5v8uTJ5Ofnu7aMjIx6rFJEREQaiyYzhLywsJAVK1awevVq7rjjDsA5541hGPj6+jJv3jzOOuusaufZbDZsNltDlysiIiImazIhJywsjHXr1rnte+211/jhhx+YNWsW7du3N6kyERERaYxMDTlFRUVs3brV9XzHjh2kpaXRqlUr2rVrx+TJk9mzZw/vvfceVquVnj17up0fExNDQEBAtf0iIiIipoacFStWMHz4cNfziRMnAjB+/Hjeffdd9u3bR3p6ulnliYiISBNmMQzDMLuIhlRQUEB4eDj5+fmaDFBERKSJqMvf7yYzukpERESkNhRyREREpFlSyBEREZFmSSHHS+wOg+yCUnbmFptdioiIiKCQ4zXLtu1n4DMLufn9FWaXIiIiIijkeE1MmHNW5ezCMpMrEREREVDI8ZqYUGfIySupoKzSbnI1IiIiopDjJeGBfvj7OC9nblG5ydWIiIiIQo6XWCwWog/fzckuKDW5GhEREVHI8SJXyFG/HBEREdMp5HhRjEKOiIhIo6GQ40VVI6xy1FwlIiJiOoUcL4oJDQB0J0dERKQxUMjxIjVXiYiINB4KOV7kaq5SyBERETGdQo4XRYdUNVepT46IiIjZFHK8qOpOTm5ROXaHYXI1IiIiLZtCjhe1DvbHYnGuSH6gWLMei4iImEkhx4t8fay0Dq7qfKwmKxERETMp5HiZRliJiIg0Dgo5XnZkQkCFHBERETMp5HjZkTs5aq4SERExk0KOl1Ut0qm5ckRERMylkONlWtpBRESkcVDI8TJ1PBYREWkcFHK8rKrjsfrkiIiImEshx8tczVUFZRiGZj0WERExi0KOl1V1PC6rdFBQWmlyNSIiIi2XQo6XBfj5EBbgC0COmqxERERMo5BTD2LCjjRZiYiIiDkUcupBdMjhuXKKFHJERETMopBTD1wjrHQnR0RExDQKOfVASzuIiIiYTyGnHmjWYxEREfMp5NQDNVeJiIiYTyGnHkSruUpERMR0Cjn1QM1VIiIi5lPIqQdVd3IKSysprbCbXI2IiEjLpJBTD8ICfLH5Oi9tju7miIiImEIhpx5YLBatRi4iImIyhZx6cvRq5CIiItLwFHLqyZEJARVyREREzKCQU08067GIiIi5FHLqiVYiFxERMZepIWfJkiWMGTOGhIQELBYLs2fPPu7xX3zxBeeccw7R0dGEhYUxaNAg5s6d2zDF1lK0mqtERERMZWrIKS4uJiUlhVdffdWj45csWcI555zDnDlzWLlyJcOHD2fMmDGsXr26niutvaqQoyHkIiIi5vA188NHjx7N6NGjPT5++vTpbs+feeYZvvrqK7755hv69u3r5epOjjoei4iImMvUkHOyHA4HhYWFtGrV6pjHlJWVUVZ2JGgUFBQ0RGmuIeT7i8uotDvw9VH3JxERkYbUpP/y/u1vf6OoqIgrrrjimMdMnTqV8PBw15aYmNggtbUO9sfHasEwYH9xeYN8poiIiBzRZEPORx99xBNPPMGnn35KTEzMMY+bPHky+fn5ri0jI6NB6rNaLUSF+AMaYSUiImKGJtlc9cknn3DjjTfy2WefMWLEiOMea7PZsNlsDVSZu5jQALIKyg7PlRNuSg0iIiItVZO7k/Pxxx9z/fXX8/HHH3P++eebXc5xqfOxiIiIeUy9k1NUVMTWrVtdz3fs2EFaWhqtWrWiXbt2TJ48mT179vDee+8Bziaq8ePH8/e//53U1FQyMzMBCAwMJDy88d0pcc2Vo+YqERGRBmfqnZwVK1bQt29f1/DviRMn0rdvXx577DEA9u3bR3p6uuv4t956i8rKSiZMmEB8fLxru/vuu02p/0Sq7uTkFGlpBxERkYZm6p2cYcOGYRjGMV9/99133Z4vWrSofgvysmgt7SAiImKaJtcnpylRnxwRERHzKOTUoxgt7SAiImIahZx6VLUSeU5h2XGb5URERMT7FHLqUXSI805Oud1BXkmFydWIiIi0LAo59cjf10pkkB+gfjkiIiINTSGnnrnmyinUMHIREZGGpJBTz6pWI1fnYxERkYalkFPPNIxcRETEHAo59Sw6TEs7iIiImEEhp55VNVepT46IiEjDUsipZ2quEhERMYdCTj3TrMciIiLmUMipZ64h5AVqrhIREWlICjn1rGpph+JyO8VllSZXIyIi0nIo5NSzEJsvQf4+gJqsREREGpJCTgNQ52MREZGGp5DTADSMXEREpOEp5DQATQgoIiLS8BRyGoCaq0RERBqeQk4D0ErkIiIiDU8hpwFoJXIREZGGp5DTAFzNVeqTIyIi0mAUchpAzOGOxzlFCjkiIiINRSGnAVQ1Vx0oLqe80mFyNSIiIi2DQk4DiAzyw8/HAkCu7uaIiIg0CIWcBmCxWIgO0TByERGRhqSQ00CiDy/UqdXIRUREGoZCTgPRnRwREZGGpZDTQKpGWCnkiIiINAyFnAZSNVdOjmY9FhERaRAKOQ1Esx6LiIg0LIWcBqJFOkVERBqWQk4DcfXJ0dIOIiIiDUIhp4FUNVflFpXhcBgmVyMiItL8KeQ0kNYh/lgsUOkwOFBSbnY5IiIizZ5CTgPx87HSKsgfUJOViIhIQ1DIaUDRrs7HGkYuIiJS3xRyGlBM1dIOGmElIiJS7xRyGtCRCQEVckREROqbQk4DUsgRERFpOAo5DShGfXJEREQajEJOA3L1ydHoKhERkXqnkNOAorW0g4iISIMxNeQsWbKEMWPGkJCQgMViYfbs2Sc8Z9GiRfTr1w+bzUanTp149913671Obzm6ucowNOuxiIhIfTI15BQXF5OSksKrr77q0fE7duzg/PPPZ/jw4aSlpXHPPfdw4403Mnfu3Hqu1DuqlnYorXBQWFZpcjUiIiLNm6+ZHz569GhGjx7t8fFvvPEG7du358UXXwSgW7duLF26lJdeeomRI0fWV5leE+jvQ6jNl8KySnIKywgL8DO7JBERkWarSfXJWbZsGSNGjHDbN3LkSJYtW2ZSRbUXrdXIRUREGoSpd3JqKzMzk9jYWLd9sbGxFBQUcOjQIQIDA6udU1ZWRlnZkUBRUFBQ73UeT0yoje05xRpGLiIiUs+a1J2cupg6dSrh4eGuLTEx0dR6qvrlaEJAERGR+tWkQk5cXBxZWVlu+7KysggLC6vxLg7A5MmTyc/Pd20ZGRkNUeoxaRi5iIhIw2hSzVWDBg1izpw5bvvmz5/PoEGDjnmOzWbDZrPVd2kecw0jL1BzlYiISH0y9U5OUVERaWlppKWlAc4h4mlpaaSnpwPOuzDjxo1zHX/rrbeyfft2/u///o9Nmzbx2muv8emnn3LvvfeaUX6dxITpTo6IiEhDMDXkrFixgr59+9K3b18AJk6cSN++fXnssccA2LdvnyvwALRv357vvvuO+fPnk5KSwosvvsg//vGPJjF8vEpVnxyFHBERkfplanPVsGHDjjvzb02zGQ8bNozVq1fXY1X1SyuRi4iINIwm1fG4Oai6k5N/qILSCrvJ1YiIiDRfCjkNLCzQF39f52XX3RwREZH6o5DTwCwWy1ELdSrkiIiI1BeFHBNEu/rlaBi5iIhIfVHIMYHu5IiIiNQ/hRwTuIaRa5FOERGReqOQY4Ijd3LUXCUiIlJfFHJMUDXrsUZXiYiI1B+FHBNo1mMREZH6p5BjAq1ELiIiUv8UckxQ1Sdnf1EZdsexl7UQERGRulPIMUHrEBtWCzgMZ9ARERER71PIMYGP1ULrEDVZiYiI1CeFHJNoGLmIiEj9UsgxiSvkaEJAERGReqGQY5KqYeSaK0dERKR+KOSYpGpCQPXJERERqR8KOSZRnxwREZH6pZBjEk0IKCIiUr8UckwSrZXIRURE6pVCjkmqmqtyCsswDM16LCIi4m0KOSapaq4qtzvIP1RhcjUiIiLNj0KOSQL8fAgP9APUL0dERKQ+KOSY6OgmKxEREfEuhRwTHZkrR8PIRUREvE0hx0TRIVraQUREpL4o5JgoJuzwMHI1V4mIiHidQo6JYjQhoIiISL1RyDGRa9bjAvXJERER8TaFHBNpJXIREZH6o5BjIq1ELiIiUn8UckxU1SenqKySkvJKk6sRERFpXhRyTBRi8yXAz/mPQE1WIiIi3qWQYyKLxeLql6MmKxEREe9SyDGZaxi5JgQUERHxKoUck2lpBxERkfqhkGMyNVeJiIjUD4Uck0WruUpERKReKOSYrKpPTk6RQo6IiIg3KeSYzLVIp5Z2EBER8SqFHJNFhxy+k6M+OSIiIl6lkGOyqtFV+4vLqbA7TK5GRESk+VDIMVmrIH98rRYActUvR0RExGsUckxmtVqICtEIKxEREW8zPeS8+uqrJCcnExAQQGpqKsuXLz/u8dOnT6dLly4EBgaSmJjIvffeS2lp0+60q9XIRUREvM/UkDNz5kwmTpzIlClTWLVqFSkpKYwcOZLs7Owaj//oo4+YNGkSU6ZMYePGjfzzn/9k5syZPPTQQw1cuXe5lnbQrMciIiJeY2rImTZtGjfddBPXX3893bt354033iAoKIh33nmnxuN//vlnBg8ezNVXX01ycjLnnnsuV1111Qnv/jR20YdnPdYIKxEREe8xLeSUl5ezcuVKRowYcaQYq5URI0awbNmyGs85/fTTWblypSvUbN++nTlz5nDeeecd83PKysooKChw2xob16zHCjkiIiJe42vWB+fm5mK324mNjXXbHxsby6ZNm2o85+qrryY3N5czzjgDwzCorKzk1ltvPW5z1dSpU3niiSe8Wru3aSVyERER7zO943FtLFq0iGeeeYbXXnuNVatW8cUXX/Ddd9/x17/+9ZjnTJ48mfz8fNeWkZHRgBV7xrW0g/rkiIiIeI1pd3KioqLw8fEhKyvLbX9WVhZxcXE1nvPoo49y7bXXcuONNwLQq1cviouLufnmm3n44YexWqtnNpvNhs1m8/4v4EWupR3UXCUiIuI1pt3J8ff3p3///ixcuNC1z+FwsHDhQgYNGlTjOSUlJdWCjI+PDwCGYdRfsfXsyJ2cMhyOpvt7iIiINCZ1upOTkZGBxWKhbdu2ACxfvpyPPvqI7t27c/PNN3v8PhMnTmT8+PGceuqpDBw4kOnTp1NcXMz1118PwLhx42jTpg1Tp04FYMyYMUybNo2+ffuSmprK1q1befTRRxkzZowr7DRFVZMBVjoMDpaU0zqkcd95EhERaQrqFHKuvvpqbr75Zq699loyMzM555xz6NGjBx9++CGZmZk89thjHr3P2LFjycnJ4bHHHiMzM5M+ffrwn//8x9UZOT093e3OzSOPPILFYuGRRx5hz549REdHM2bMGJ5++um6/BqNhr+vlVbB/hwoLie7sEwhR0RExAssRh3aeSIjI/nll1/o0qULL7/8MjNnzuSnn35i3rx53HrrrWzfvr0+avWKgoICwsPDyc/PJywszOxyXEZNX8KmzELeu2EgQzpHm12OiIhIo1KXv9916pNTUVHh6sy7YMECLrzwQgC6du3Kvn376vKWLV7VXDmZBRphJSIi4g11Cjk9evTgjTfe4L///S/z589n1KhRAOzdu5fWrVt7tcCWoktsKABLt+SaXImIiEjzUKeQ89xzz/Hmm28ybNgwrrrqKlJSUgD4+uuvGThwoFcLbCnO6x0PwIKNWRwqt5tcjYiISNNXp47Hw4YNIzc3l4KCAiIjI137b775ZoKCgrxWXEvSNzGCNhGB7Mk7xI+bszmvV7zZJYmIiDRpdbqTc+jQIcrKylwBZ9euXUyfPp3NmzcTExPj1QJbCovFwgUpzmDz7dq9JlcjIiLS9NUp5Fx00UW89957AOTl5ZGamsqLL77IxRdfzOuvv+7VAluSMb0TAPhhUzbFZZUmVyMiItK01SnkrFq1ijPPPBOAWbNmERsby65du3jvvfd4+eWXvVpgS9IjIYzk1kGUVjhYsDHrxCeIiIjIMdUp5JSUlBAa6hwNNG/ePC699FKsViunnXYau3bt8mqBLYnFYuGCw3dzvlmjofgiIiIno04hp1OnTsyePZuMjAzmzp3LueeeC0B2dnajmmCvKarql7Pk9xzyD1WYXI2IiEjTVaeQ89hjj3H//feTnJzMwIEDXQtqzps3j759+3q1wJamS2wonWJCKLc7mP+bmqxERETqqk4h5/LLLyc9PZ0VK1Ywd+5c1/6zzz6bl156yWvFtUTOJiuNshIRETlZdQo5AHFxcfTt25e9e/eye/duAAYOHEjXrl29VlxLVdUvZ+mWXA4Wl5tcjYiISNNUp5DjcDh48sknCQ8PJykpiaSkJCIiIvjrX/+Kw+Hwdo0tTqeYELrFh1HpMJi7IdPsckRERJqkOs14/PDDD/PPf/6TZ599lsGDBwOwdOlSHn/8cUpLS3n66ae9WmRLdEHveDbuK+Dbtfu4cmA7s8sRERFpciyGYRi1PSkhIYE33njDtfp4la+++orbb7+dPXv2eK1Ab6vLUu1mSN9fwpAXfsRqgeUPjyAqxGZ2SSIiIqapy9/vOjVXHThwoMa+N127duXAgQN1eUv5g3atg+jdNhyHAd+vV5OViIhIbdUp5KSkpDBjxoxq+2fMmEHv3r1Puqgmq7IMKkq99nZVo6y+WaNRViIiIrVVpz45zz//POeffz4LFixwzZGzbNkyMjIymDNnjlcLbDJyt8Cs6yExFc5/0StveX7vBJ6Zs4n/7TxAVkEpsWEBXnlfERGRlqBOd3KGDh3K77//ziWXXEJeXh55eXlceumlbNiwgffff9/bNTYNeemQuQ7+9w/Y+I1X3rJNRCD92kVgGPDdWi3zICIiUht16nh8LGvWrKFfv37Y7XZvvaXX1WvH43mPws8vQ0AE3PYThLc96bd8Z+kOnvz2N/q1i+CL2weffI0iIiJNUIN1PJZjOOtRSOgHpXnw+U1grzzptzy/dzwWC6xKz2NP3qGTr1FERKSFUMjxJl9/uPyf4B8K6T/Df/920m8ZGxbAgORWAHynZR5EREQ8ppDjba06wAXTnI8XPwc7fzrptxyT4lzm4Vv1yxEREfFYrUZXXXrppcd9PS8v72RqaT56XwHbfoQ1H8EXN8GtSyGoVZ3fbnTPOKZ8tZ61u/PZtb+YpNbBXixWRESkearVnZzw8PDjbklJSYwbN66+am1aznsBWnWEgj3w9Z1wEv27o0JsnN4xCtDdHBEREU95dXRVU9CgyzrsTYN/jABHhXPunAE31vmtPlmezqQv1tE1LpT/3DPEezWKiIg0ARpd1dgk9IFznnQ+/s9DkLWhzm81qmccvlYLmzIL2Zpd5J36REREmjGFnPp22m1wyrlgL4NZN0B5SZ3eJiLInzNOqWqy0igrERGRE1HIqW8WC1z8OoTEQs4mmDu5zm91Qe8jo6xaWCujiIhIrSnkNITgKLj0LcACK9+FDbPr9Dbn9ojF38fK1uwiNmcVerNCERGRZkchp6F0GAZn3Ot8/M1dzrWuaikswI8hnaMB+HaNRlmJiIgcj0JOQxr+ELQdAKX58PmNdVr2YUxKPODsl6MmKxERkWNTyGlIPn5w2T/AFgYZv8LiZ2v9FiO6xRLgZ2Xn/hI27C2ohyJFRESaB4WchhaZDGOmOx8v+Rvs+G+tTg+2+XJW1xgAvtEoKxERkWNSyDFDz8ug77WA4Vz2oXh/rU53jbJao1FWIiIix6KQY5bRz0FUZyjcB19NqNWyD8O7xBDk78OevEOszsirvxpFRESaMIUcs/gHw+XvgI8//P49LH/L41MD/X0Y0S0W0CgrERGRY1HIMVNcLzj3KefjeY9A5jqPT72gt3OU1Zx1+3A41GQlIiLyRwo5Zht4M3QeDfZy+Ox6KPVsxNTQLtGE2nzJLChlxa6D9VykiIhI06OQYzaLBS56FULjYf8WeGso7Fl5wtNsvj6c0+Nwk5VGWYmIiFSjkNMYBLeGqz6GsLZwYDv881xYOh0cjuOeNibFOcpqzrpM7GqyEhERcaOQ01gk9IXblkL3i8FRCQumwPsXQ8GxOxaf0SmKiCA/covK+HV77Yahi4iINHcKOY1JYCT86V248BXwC4Idi+H102Hz9zUe7udjZVSPOAC+WatRViIiIkdTyGlsLBboNw5uXuwcfXXoAHx8Jcx5ACoOVTu8amLA/6zfR4X9+M1bIiIiLYnpIefVV18lOTmZgIAAUlNTWb58+XGPz8vLY8KECcTHx2Oz2ejcuTNz5sxpoGobUHRnuHEhDLrD+Xz5W/D2WZC90e2w0zq0onWwPwdLKvhpa64JhYqIiDROpoacmTNnMnHiRKZMmcKqVatISUlh5MiRZGdn13h8eXk555xzDjt37mTWrFls3ryZt99+mzZt2jRw5Q3E1wYjn4ZrPofgaMj+Dd4aBv/7h2uGZF8fK6N7OZusvlWTlYiIiIvFMHHxo9TUVAYMGMCMGTMAcDgcJCYmcueddzJp0qRqx7/xxhu88MILbNq0CT8/vzp9ZkFBAeHh4eTn5xMWFnZS9TeoomyYfTtsne983uV8uGgGBLXil+37ufKtXwj292H+xKEkRASaW6uIiIiX1eXvt2l3csrLy1m5ciUjRow4UozVyogRI1i2bFmN53z99dcMGjSICRMmEBsbS8+ePXnmmWew2+3H/JyysjIKCgrctiYpJAau/hRGTnUuBbH5O2en5B1LGJjcir7tIigutzPpi3VatFNERAQTQ05ubi52u53Y2Fi3/bGxsWRmZtZ4zvbt25k1axZ2u505c+bw6KOP8uKLL/LUU08d83OmTp1KeHi4a0tMTPTq79GgrFYYdDvcuABan+Jc3PPfF2L94UleuKQ7/r5Wlvyew8z/ZZhdqYiIiOlM73hcGw6Hg5iYGN566y369+/P2LFjefjhh3njjTeOec7kyZPJz893bRkZzSAAxKfALYuh33jAgKXT6PTtZTxxhrOZ6qnvNrInr/pILBERkZbEtJATFRWFj48PWVlZbvuzsrKIi4ur8Zz4+Hg6d+6Mj4+Pa1+3bt3IzMykvLy8xnNsNhthYWFuW7PgHwwXvgx/+jcEhMOelVy58ioeiVpMSVk5kz5fq2YrERFp0UwLOf7+/vTv35+FCxe69jkcDhYuXMigQYNqPGfw4MFs3boVx1HLHfz+++/Ex8fj7+9f7zU3Sj0uhtt+huQzsVSUcGPRm8yyPcnerWv4RM1WIiLSgpnaXDVx4kTefvtt/v3vf7Nx40Zuu+02iouLuf766wEYN24ckydPdh1/2223ceDAAe6++25+//13vvvuO5555hkmTJhg1q/QOIS3hXFfw/nTwD+UfpbfmeM/maxvn2Z3br7Z1YmIiJjC18wPHzt2LDk5OTz22GNkZmbSp08f/vOf/7g6I6enp2O1HslhiYmJzJ07l3vvvZfevXvTpk0b7r77bh588EGzfoXGw2qFAX+BziMxvrkX29Z53GP5hJ1v/g/j+newJPQxu0IREZEGZeo8OWZosvPk1IZhkP3Te/jNf4hISxEOiw/WwXfD0AfBL8Ds6kRERGqtSc2TI/XIYiHmjPF8N+QrvrWfhtWww9Jp8MYZkP6L2dWJiIg0CIWcZuyq4f15N2EKN5ffy0FrK9i/Bd4ZBXP+D8qKzC5PRESkXinkNGM+Vgsv/CmFJT6pDC15lq1tLgEMWP4mvDYItv1gdokiIiL1RiGnmWsfFcwDI7tSQAgXZlxJ9sWfQEQ7yE+H9y+B2RPg0EGzyxQREfE6hZwW4PrTkxmQHElJuZ27l0fiuPVnSL0VsEDaB/BqKmz81uwyRUREvEohpwWwWi28cHkKAX5Wlm3fz4er98Po5+CG/zjXwCrKgpnXwL8vhPRfzS5XRETEKxRyWojkqGAeHNUVgKnfbyLjQAm0Ow1uXQpnTASrH+xYDO+cCx9cBntWmlyxiIjIyVHIaUHGD0pmYPtWlJTbeWDWGhwOwzlvzogpcNcq6DcOLD6wdQG8fRZ8dCXsW2t22SIiInWikNOCOJutehPo58Mv2w/wwa+7jrwY0Q4ufAXuXAEpV4PFCr9/D2+eCTP/DFm/mVe4iIhIHSjktDBJrYN5cFQXAKbO2UT6/hL3A1p1gEtehwnLodefAAts/AZePx1m3QA5vzd80SIiInWgkNMCjRuUTGr7VhyqOKrZ6o+iToHL/gG3L4PuFwEGrP8cXkuFL26B/dsavG4REZHaUMhpgapGWwX6+fDrjgO8t2znsQ+O6QZXvOfsoNzlfDAcsPYTmDEAvpoAB3cd+1wRERETKeS0UO1aBzFptHO01XP/2cyu/cXHPyGuF1z1Edz0I5xyLhh2WP0BvNIPvrkH8nfXf9EiIiK1oJDTgl17WhKndahqtlpbc7PVH7XpB9d8Bn+ZDx2Gg6MSVv4LXu4H8x+DQ3n1XreIiIgnFHJaMKvVwvOXpRDk78PyHQd456cdnp+cOBDGzYbr5kDSYLCXwU9/h5f7wM8zoLKsvsoWERHxiEJOC9eudRCTz+sGwPP/2czGfQW1e4PkwXDdd3D1pxDdzbkO1ryHYcapsPYzcDjqoWoREZETU8gR/pzajrO6xlBud3DPJ2mUVthr9wYWC3QeCbf9BBfOgNB4yEuHL26Et4fB9kX1UbaIiMhxKeQIFouF5y/vTVSIP5uzCnn2+011eyOrD/S7Fu5cBWc9Cv6hsG8NvHeRc6mIzPXeLVxEROQ4FHIEgKgQGy9cngLAuz/vZNHm7Lq/mX8QDLkf7k5zrnZu9XMuFfHGGfDlbRqJJSIiDUIhR1yGd41h/KAkAO7/bC37i06y83BwlHO18zuWQ49LAQPWfKSRWCIi0iAUcsTN5PO6cUpMCLlFZTz4+VoMw4Nh5SfSqgP86V9w0w+QdIb7SKxlr2okloiI1AuFHHET4OfD36/si7+PlQUbs/nw13TvvXmb/nDdt+4jseY+5ByJtfFb732OiIgICjlSg+4JYfzf4UU8n/ruN7ZmF3rvzY81EmvmNfDJNVCw13ufJSIiLZpCjtTohsHtOfOUKEorHNz1cRpllbUcVn4iR4/EOvN+sPrCpm9hxkBY/rbm1xERkZOmkCM1slot/O1PKUQG+fHbvgKmzfu9fj7IPwjOfhRu+S+0HQDlhTDnfnhnJGT9Vj+fKSIiLYJCjhxTbFgAz17WG4C3/rudn7fm1uOHdYcb5sF5f3POr7N7Obx5Jiz8K1SU1t/niohIs6WQI8c1skccVw1MxDBg4qdryCspr78Ps1ph4E3OIeddL3Au/vnfv8Hrp8OO/9bf54qISLOkkCMn9OgF3ekQFUxmQSmTv1jnnWHlxxOWAFd+CGM/cHZMPrAN/n0BfDUBSg7U72eLiEizoZAjJxTk78v0K/vga7Xw/fpMPlvZQDMWdxsDE36FATcCFlj9AcwYAOtmQX0HLRERafIUcsQjvdtGMPHczgA8/vUGduYWN8wHB4TD+S/CDXOdc+uU5MLnf4EPL4eDuxqmBhERaZIUcsRjtwzpSGr7VpSU27l7ZhoV9gYc5t0uFW5ZAsMfAR9/51pYr50GP78C9sqGq0NERJoMhRzxmI/Vwktj+xAW4MuajDxeWbilYQvw9YehD8BtPzuXh6gogXmPwBuDYckLkL1JzVgiIuJiMeq9F2njUlBQQHh4OPn5+YSFhZldTpP07dq93PHRaqwWmHnLIAYkt2r4IgzD2Udn3iNQmndkf+tOzpFZ3cZAQj/niC0REWny6vL3WyFH6uS+T9fw+ardtIkI5Pt7ziQswM+cQkoOwMZvnLMlb18E9qOGuIcmQNfznIEnaTD4mFSjiIicNIUcDyjkeEdhaQXnv7yU9AMlXNwngelX9jW7JCgtgK3znYt9bpkH5UVHXguIgC6jnXd5Op7lnGlZRESaDIUcDyjkeM/KXQe54s1l2B0G08f24eK+bcwu6YjKMti+GDZ+DZu/d47KquIX5Aw63cY4FwsNjDSvThER8YhCjgcUcrxr+oLfmb5gC4F+Prw0NoVRPePNLqk6hx3Sf3E2aW38FvLTj7xm9YXuF8OQByCmq2kliojI8SnkeEAhx7sq7Q7+8u8VLP49B4C7zj6Fe84+BavVYnJlx2AYkLnWGXY2fQvZVYuAWqD7Rc6wE9fT1BJFRKQ6hRwPKOR4X6XdwTNzNvHOTzsAOKd7LNOuSCHUrM7ItbFvDSz5m7NZq0rXC2DogxDf27y6RETEjUKOBxRy6s/nK3cz+ct1lFc66BQTwtvjTqV9VLDZZXkma4Nzrp0Ns4HD/0p0Oc95Z6dNPzMrExERFHI8opBTv9Iy8rjl/RVkFZQRFuDLK1f3Y2jnaLPL8lz2JufK5+s/B+PwjM6nnAtD/g8SB5hbm4hIC6aQ4wGFnPqXXVDKrR+sZFV6HlYLPDiqKzcP6YDF0kj76dQkdwv890VYO/NI2Ol4lrMZq91p5tYmItICKeR4QCGnYZRV2pny1QY++V8GABemJPDcZb0J9PcxubJa2r8N/jsN1nwMht25r/0QZ9hJPsPc2kREWpC6/P1uFHPev/rqqyQnJxMQEEBqairLly/36LxPPvkEi8XCxRdfXL8FSq3ZfH2Yemkv/npRD3ytFr5es5fL3/iZPXmHzC6tdlp3hItfhbtWQb/xYPWDHUvg3fPhX+c55+IREZFGyfSQM3PmTCZOnMiUKVNYtWoVKSkpjBw5kuzs7OOet3PnTu6//37OPPPMBqpUastisXDtoGQ+uDGVVsH+bNhbwIWvLGX5jgNml1Z7kclw4cvOsHPqX5wroe/6Cd67ED643NmXR0REGhXTm6tSU1MZMGAAM2bMAMDhcJCYmMidd97JpEmTajzHbrczZMgQbrjhBv773/+Sl5fH7NmzPfo8NVeZY/fBEm5+byW/7SvA12phyoU9+HNqu6bVT+do+Xvgp+mw4h1wVILFB/pfB8MfguAos6sTEWl2mlxzVXl5OStXrmTEiBGufVarlREjRrBs2bJjnvfkk08SExPDX/7yl4YoU7ygbWQQn992Ohf0jqfSYfDo7PU8dHi4eZMU3gbOewEmLHfOq2PYYcU/4eW+8NPfnctKiIiIqUwNObm5udjtdmJjY932x8bGkpmZWeM5S5cu5Z///Cdvv/22R59RVlZGQUGB2ybmCPT34ZWr+vLgqK5YLPDx8gyuevsXsgtLzS6t7lp3hCs/hPHfQlxvKCuA+Y/BjAGw4UvnDMsiImIK0/vk1EZhYSHXXnstb7/9NlFRnjUJTJ06lfDwcNeWmJhYz1XK8VgsFm4b1pF3rhtAaIAvK3cd5MJXfuJ/O5tgP52jtT8Tbl4MF78OofGQtws+uw7eGQW7V5pdnYhIi2Rqn5zy8nKCgoKYNWuW2wip8ePHk5eXx1dffeV2fFpaGn379sXH58gwZIfD2dxhtVrZvHkzHTt2dDunrKyMsrIjTQcFBQUkJiaqT04jsD2niJveW8G2nGIsFhg/KJkHRnYh2OZrdmknp7wYfn7F2WxVUeLc1+sKOPsxiFDIFhGpiybXJ8ff35/+/fuzcOFC1z6Hw8HChQsZNGhQteO7du3KunXrSEtLc20XXnghw4cPJy0trca7NDabjbCwMLdNGocO0SHMnjCYK05ti2HAuz/v5NyXlrDk8GKfTZZ/MAybBHeuhJSrnfvWfQozToWFf4WyQnPrExFpIUwfXTVz5kzGjx/Pm2++ycCBA5k+fTqffvopmzZtIjY2lnHjxtGmTRumTp1a4/nXXXedRlc1A//dksPkL9ax+6BzHp3L+7fl0fO7Ex7UBBb5PJG9q2HuI7BrqfN5SCyc9Qj0uQasTWxyRBERk9Tl77fp7QJjx44lJyeHxx57jMzMTPr06cN//vMfV2fk9PR0rNYm1XVI6uDMU6KZe88QXpi7mX8v28mslbtZ/HsOf72oJ6N6xpld3slJ6AvXfQubvoP5j8KB7fD1nfDrm9D3z9CqI7TqABHtwNff7GpFRJoN0+/kNDTdyWn8Vuw8wP99vpbtOcUAnN8rnscv7EF0qM3kyrygshz+9zYsfg5K891fs1ghPNEZeP64RSaDX4ApJYuINAZau8oDCjlNQ2mFnVd+2MIbi7djdxhEBPnx2AXduaRvm6Y7geDRSg7A8rchaz0c2OG8u1NRfJwTLBDWBlq1PxJ8Yns4Fw1Vk5eItAAKOR5QyGla1u/J5/9mreW3fc75jYZ1iebpS3rRJiLQ5Mq8zDCgKMsZdqptO5zz79QkPgVGP6+V0UWk2VPI8YBCTtNTYXfw1pLt/H3hFsorHQT7+zDpvG5cM7AdVmszuKtzIoYBJfvdg8/+bbBl3pHw0/NyOOdJ50zMIiLNkEKOBxRymq6t2UU8+PlaVu46CMDA9q147rLetI8KNrkykxTlwA9Pwqr3AQP8guCMiXD6HeDXzO50iUiLp5DjAYWcps3uMHh/2U6en7uZknI7Nl8rE4Z34tJ+bWgbGWR2eebYmwbfPwgZvzifR7SDc5+CbhdCc+i/JCKCQo5HFHKah4wDJUz+Yh1Lt+a69vVICGNkjzhG9YzjlJiQ5tFB2VOGAes/d66bVbDHuS/5TBj9nLODsohIE6eQ4wGFnObDMAxmp+3h4+UZrNh5AMdR3+T2UcGc2yOWkT3i6NM2omX03QHnkhJLp8PPL0NlqXNY+qk3wPCHIaiV2dWJiNSZQo4HFHKap/1FZSzYmMXcDVks3ZJLud3hei02zMY53Z2B57QOrfHzaQGTSx7c5Zx48LfD678FRjqDTv/rwcf0OUBFRGpNIccDCjnNX1FZJYs2ZzN3QxY/bsqmqKzS9VpYgC9nd4tlZI9YhnSOJsi/mf/B37EEvp8E2Rucz2O6w6hnocNQc+sSEaklhRwPKOS0LGWVdn7etp+56zOZ/1sW+4vLXa8F+Fk585RobjqzAwPbN+OmHHslrHoXfngKDjlHptFtDKTeBpFJEBqvCQVFpNFTyPGAQk7LZXcYrNx1kLkbMpm7IdO1GCjAn09rx4OjuhIa0AwWBD2WkgOw6Fn43z/AsB/Zb/V1zqYc0e7IFp54+HGi8zWfZnxdRKRJUMjxgEKOgLPT8m/7Cnjv513MXJEBQEJ4AE9f2ovhXWJMrq6eZf0Gi6ZC5lrI3w2OyuMfb7FCaMKR0BPRDiLbQ6cREBrbMDWLSIunkOMBhRz5o5+35jLpi3WkHygB4NK+bXj0gu5EBreAFcEddijMhLx0yM+AvF2Ql3HU8wywlx3jZAskDYYeFzvn5FHgEZF6pJDjAYUcqUlJeSUvzvudd37agWFAVIg/T17Uk/N6xZtdmrkcDijOORx60p0/8zJgXxrsWXnkOIvVPfCENPO7YSLS4BRyPKCQI8ezKv0gD85ay5bsIgBG9YjjyYt6EBMWYHJljVBeunOI+obZsGfFkf0KPCJSDxRyPKCQIydSVmnn1R+28tqibVQ6DMICfHn0gu5c3r9ty5pFuTYO7nIGnt9mV7/Dk3wGdL/4cOCJNqtCEWniFHI8oJAjnvptbwEPfr6WdXvyATjzlCieuaQXia1a6BpZnjq488gdnr2rjuyvCjw9LoFTznWO2lJoFBEPKeR4QCFHaqPS7uAfS3fw0vzfKat0EOTvw4OjunLtaUktZ6mIk3FwpzPs/DYb9q52fy0oCuJTIL6382dcb+eoLWsLmJFaRGpNIccDCjlSF9tzipj0+TqW7zwAwKlJkTx3eW86RoeYXFkTcmDHkSatfWvd5+qpYguDuF6Hw8/h4BPVWUtRiIhCjicUcqSuHA6DD3/dxbPfb6K43I6/r5XbhnbkrK4xdI0PxearWYM9VnHIOV/PvjTnfD371jif1zRc3TfAuZL60cEnugv4Bzd42SJiHoUcDyjkyMnafbCEh75cz5Lfc1z7/H2sdEsIo0/bcFISI0hJjKB962A1adWGvQJyNh8JPfvWOh+XF9V8fHgiRJ0CUV2cP6O7OO/6BEerr49IM6SQ4wGFHPEGwzD4Km0vs9P2sCYjj4MlFdWOCQ3wJaVtBCmJ4aS0jaBPYoSGoteWwwEHdzjv+Ow7HH4y10FJ7rHPCYhwhp3ozs6fVSEoMllrdIk0YQo5HlDIEW8zDIOMA4dI253Hmgzntm5PPmWVjmrHxocHHA4+zvDTJzGi+a+EXh9KDkDu7847P7m/H9kO7gKO8Z80Hxu07uicw2fYZAhu3aAli8jJUcjxgEKONIQKu4PfswpZk5HvDD678/g9qxDHH/5t8/Ox0K9dJIM7RTG4UxQpbcPx9dHoojqrOAT7t0HuZsjdcjgEbYH9W6Cy9MhxQa1h5FTofYWatkSaCIUcDyjkiFmKyypZvyefNbvzWJORz6r0g+zLL3U7JtTmS2qHVq7Qc0pMiCYg9AaH3bkWV+Z6+PEZyN7g3N9hOFzwErRqb259InJCCjkeUMiRxsIwDHbtL2Hp1lx+3pbLz9v2k/eHvj3RoTYGd2ztCj0JEYEmVduM2Cvg55dh0XPO0Vy+gTBsEgyaAD5+ZlcnIsegkOMBhRxprOwOg9/2FvDTtlx+2prL8h0HqvXr6RAVfDjwtGZQhyjCg/RHuc72b4Nv74EdS5zPY3vBhX+HNv1NLUtEaqaQ4wGFHGkqSivsrEo/yE9bc/lp637W7s5z69NjtUCfxAiGdo5haJdoerUJx0dD1mvHMGDNxzD3ITh00Ln0ROqtMPxhsGmiR5HGRCHHAwo50lTlH6rg1+37+WlrLku35rItp9jt9cggP848JZqhnaMZ0jma6FCbSZU2QUU5zqCz7lPn8/BEOP9F6DzS3LpExEUhxwMKOdJc7M07xJLfc1j8ew5Lt+RSWFbp9nqPhDCGdYlmaOcY+raLwE+jtk5s6wL49l7IS3c+73EJjHoOQmPNrUtEFHI8oZAjzVGF3UFaRh6LN+ew6Pds1u8pcHs91ObL4E5RDO3ivMvTRh2Yj628GBZNhWWvguGAgHA456/Q91otHipiIoUcDyjkSEuQU1jGf7c47/Is+T2n2ozMp8SEkJIYQdvIQNpEBNI2Moi2kYHEhQfojk+VvWnwzV3OWZbBOYngBdOdMymLSINTyPGAQo60NHaHwfo9+Sw+3LS1Ov1gtUkJq1gtEBcWQNvIINpEBtL28NYmwhmC4iMCWtZCpPZK+PUN+PFpqCgBqx9EJILV1/nY6uMcdl7t+TFe8wtyrq0VEg3BMUc9jtaCoyInoJDjAYUcaenySyr4eVsu23KK2H3wEHvyDrl+ltewFMXRLBaICbW57v60cYWgw88jAgn0b4Yh6OAu+G6is89OffELhuAoCDkcfqq2o59HtIPwtlqDS1okhRwPKOSI1MzhMMgtKmN3Veg5eIjdB0uOhKCDhzhUYT/h+0SF+B87BEUGEmJromt1GQbkbILSfHBUOicVdNjBUVH9uf3wvqqt6nl5ERTnQnEOFGUffpztvuTEiVj9nIuNturwh629MwQ1hgkN7RVQlAUF+6Bwr/PadRkNvhrxJ3WnkOMBhRyRujEMgwPF5W6h5+gQtPvgIYr+MMKrJhFBfodDz5G7P20jAw8HoiDCAxvBH+mGZBjO8HN06CnOcQ5rL845/DwXCjOdS1PYy4/9XlZfZ9CpFoA6QFgb8PF33gWq61IhhgFlBUfCi9vPfVCw1/mzKJtqC6W2PgXG/B2SB9fts6XFU8jxgEKOSP0wDIOCQ5Xszis5KgQdYk/V87xD1ZatqEmozfeo/kDVQ1BkkF/LXc/LYYeCPXBg+1HbjiM/Kw959j6Wo/sLHd5qfO5zpD/RoYPOMFNRfOL3B+d7hMY7t4M7nIENoN94OOcJCIys2zWQFkshxwMKOSLmKSqrdN79OXjoqP5AR57vLz7OXYrDgv196NMugtT2rUlt34o+7SJaVmfoY3E4oCjzDwHoqCBUXuS9zwoIh9AECIs/6mc8hCUc+RkUdWTI/aGDMH8KrPq383lwDIx+zjkPUUsNrFJrCjkeUMgRabxKyivZm3eIDLc7QUeCUHZhWbVzbL5W+laFng6t6NcukgA/hR43VU1ijkrniDFH5VF9iTx8HhB+JMT4B9Wtjp0/wTd3w/4tzuedR8F5f3OOWBM5AYUcDyjkiDRdpRV2duQW87+dB/h1+wF+3bGf3CL3uz/+PlZSEsNdoad/UiRB/k20s3NzVFEKS6fBf6c5g5RfMJz9KAy8WaPG5LgUcjygkCPSfBiGwbacYn7dsd8VerIK3O/2+Fot9Gp7JPR0iwsj0M8Hm58Vm6+15fbvMVv2JuddnYxfnM8T+sGFL0NcL3PrkkZLIccDCjkizZdhGOzaX+IKPb9s38/e/GMPz7ZYnM1dAX4+BPj6EODnfGzz8yGgar/fkdcD/X2ICvEnNiyAuPAA4g7/DA1oYSPCvMXhgFXvOvvrlBU4O0SfficMmwR+WnpE3CnkeEAhR6TlMAyD3QcP8cv2/fy6w3mnZ8/BQ8ec8bmugv19iK0KPWEBrsdHh6GoEH98tWRGzQr2wX8ehN++cj6PbA8XvAQdh5tblzQqCjkeUMgRkQq7g9IKO6UVVT8PP660V99f6aDs8OOScjs5hWVkFpSSVVBKZn4pBaUnnhsInEtmxIcH0jk2hK7xYXSNC6VLXCgdokLw91X4AWDTHPjuPufcOwApV8G5T0Nwa3PrkkahyYacV199lRdeeIHMzExSUlJ45ZVXGDhwYI3Hvv3227z33nusX78egP79+/PMM88c8/g/UsgREW8qKa8kq6CMzPzDwedw+Kl6nJVfSnZhGZXHuH3ka7XQMTqELodDT1X4aRMR2DL7C5UWwA9PwfK3AAMCW8GpNzhHYB09bD2olYaftzBNMuTMnDmTcePG8cYbb5Camsr06dP57LPP2Lx5MzExMdWOv+aaaxg8eDCnn346AQEBPPfcc3z55Zds2LCBNm3anPDzFHJEpKHZHQb7i8vYtb+ETZmFbM4sYNO+QjZnFlJ4jFmiQ22+dD4q+HSODSU0oO6jxHysFoL9fQmx+RIS4Nv4V5vfvQK+vguyN9T8uo8NQuPc5+YJja8+d4+Wkmg2mmTISU1NZcCAAcyYMQMAh8NBYmIid955J5MmTTrh+Xa7ncjISGbMmMG4ceNOeLxCjog0FoZhsDe/1Bl6Mp2hZ3NmIdtyiqiw1+9/mv19rYQeDjzB/s6fITbnFmzzJdRtvw8RQf5EhdiIDrHROsSf4IZYg8xeAavfh31r3JeQKMn1/D2CoyGqC8R2h9geENMDYrqBLaT+6pZ6UZe/36ZOHlFeXs7KlSuZPHmya5/VamXEiBEsW7bMo/coKSmhoqKCVq1a1fh6WVkZZWVHhpQWFBScXNEiIl5isVhoE+FcwPSsrrGu/eWVDnbkFrMps8AVfLZkF1FWeeIFUo/F7jAoKquktMLh+oz9leUezTJdk0A/H1qHOINP1OGfrV0/j+yLCrEREeiH1VqHpiUfP2dT1R9VljnX8jp6vayCve6PCzPBXnZ4/a8c2LXU/T0ikg6Hnu7OABTTA1p3Ah/NqdScmPpPMzc3F7vdTmxsrNv+2NhYNm3a5NF7PPjggyQkJDBixIgaX586dSpPPPHESdcqItJQ/H2trj463lZpd1BcZqewrILiMjtFZRUUldkpKq2kuKySwrJK5+PySgqr9pVWcLCkgtyiMnKLyiitcHCowu5amPVEfK0W4iMCaBtRfWX6tpGBxIUH1K75zNcGkUnO7VgMw7mcRN4uyN4IWRsg+zfI+s25/EXeLue2ec6Rc3z8q9/1ie7iXNzU2sib96RGTTqyPvvss3zyyScsWrSIgICAGo+ZPHkyEydOdD0vKCggMVFTiItIy+TrYyU8yEp4UN3n9ikuq2R/UTk5RWXsLyojt6j88M8ycovLyS0sY39xOblFZeSVVFDpMMg4cIiMAzUHIqsF4sICnAuyHiME1XqpDovF2Tk5qBUk9P3DL7Df2dcn67ejfm50Lj6atc65Hc3HBpHJR63q3v7I4/BE3f1pxEz9JxMVFYWPjw9ZWVlu+7OysoiLizvuuX/729949tlnWbBgAb179z7mcTabDZtNHc9ERLwl+HC/nXatT7yGVYXdQU5hGXvyqtYjKzm8Htnh53mHKK90sDe/1Dlx485jfKa/D1GhNloHH2kSiw7xP9w0dqSpLDrERlig7/FHpgW3hvZDnFsVh+PwXZ/f3MPPge3OZq/czc7tj6y+zqavVh2gdcejglAHiGjnbHIT0zSKjscDBw7klVdeAZwdj9u1a8cdd9xxzI7Hzz//PE8//TRz587ltNNOq9XnqeOxiEjj4XAY5BaXHQk9Bw+xJ6/E7fmhitr1RfLzsdA62Bl8YkJtJEcF0ykmhI7RIXSKCaF1sL/nw/PtlVCw231F96Mf26svGuti8XE2fbXpf2SL7qo1uuqoSY6umjlzJuPHj+fNN99k4MCBTJ8+nU8//ZRNmzYRGxvLuHHjaNOmDVOnTgXgueee47HHHuOjjz5i8ODBrvcJCQkhJOTEveUVckREmg7DcHaYdmsSK3I2he3/w8/cojKPJmcMD/Q7HHrcw0/byCB8atNB2uFwjvhyhZ4/BKGKkurn+AVDQh9o0+9I8AlP1Jw/HmiSIQdgxowZrskA+/Tpw8svv0xqaioAw4YNIzk5mXfffReA5ORkdu3aVe09pkyZwuOPP37Cz1LIERFpvsoq7RwoLie3sJzcYuckjdtzitiaXcS2nGIyDpZwrL96/r5WOkQF0zE6hI6HQ1D3+DA6RofUfnSYYUDBHti7GvasdM77szcNygurHxscfdTdnn7OxUqDah4x3JI12ZDTkBRyRERartIKOztyiw+HHmf42ZpdxPbcYsorHTWeEx7oR792EfRPiqR/UitSEsMJ8q9Dl1aHHXK3OENP1Za1Hhw13H1q1QGSTofeYyHpDI3uQiHHIwo5IiLyR3aHwZ6Dh1zBZ1tOEVuyi9iwN981t1AVX6uF7glhh0NPJKcmtSIuvOYRvidUUQqZ69yDz4Ft7seEJzrDTspVENWpjr9h06eQ4wGFHBER8VSF3cHGfQWs2HmQlekHWbnzIJkFpdWOaxMR6Ao9/ZMi6RoXWvdV50sOwJ5VsOkbWP8llOUfea3tAGfY6XkpBEbW8bdqmhRyPKCQIyIidVW1FMeKnQdYtesgK3YdZOO+Av64/mqwvw992kXQJzGClLbOnzFhdbjbU3HIOWHhmk9g60IwDo808/GHLqMh5WrodHaLGKqukOMBhRwREfGm4rJK0jLyXHd7Vu86WOPCqwnhAaQkRji3thH0ahtOSG3WACvMgnWfQtrH7guXBkdDrz857/DE9Wq2I7UUcjygkCMiIvXJ7jDYkl3Iyl0HWZORx5qMfH7PLqw2qstigVNiQkhp6ww+fRIj6BIX6tkSF/vWOu/urPvUuTZXlZge0Ocq6HUFhMYe+/wmSCHHAwo5IiLS0IrKKlm/J98ZenY7g8+evOrLXNh8rfRICCMlMYLebcPpEhtGx5hgbL7HmEDQXuFsxlrzsbNZy354wVWL1dlnxxYK/qHOn7aQw88P/6zaanoeEgsh0fV4RWpPIccDCjkiItIYZBeWsjYjnzW780jLyGNNRl6Nkxn6WC10iAqmS1woXeNC6RIXRte4UNpEBLrP33PoIGz40tmctXv5yRcYkQSJqdAu1fkzprupszUr5HhAIUdERBojh8Ng5/5iZ+hJz+O3fQVsyiyk8BizOAf7+9C5KvjEHgk/kcH+UJQNJfuhrPDIVl50+HERlBX84Xmhc6LCqufFOcAf4oEtDNqe6gw8ianOx7bQ+r8whynkeEAhR0REmgrDMNiXX8rmzEI2ZRayOdMZfLblFFFhr/nPd0yojS5xocSGBRAR6EdEkB/hQf6uxxGB/of3+RFqO8ZipqUFsPt/kLEcMn5xzthcXuR+jMUKsT0Oh57TnHd86nGJCoUcDyjkiIhIU1dhd7Ajt9gVfKpC0O6D1fv5HI+P1UJ4oB8Rgc7Q4wxC/kSF+LuWt+gUHUJkoA9kbYCMX51b+q+Qn179DUPjnaEn+QwYeJOXflsnhRwPKOSIiEhzVVhawe9ZRWzNLmR/cTn5JRXklVSQd6icvJIK8g8def7HmZyPp3Wwv9uaXp1iQugcWEhcwVqsu5dD+i+QufbIEhUJfeHmRV793RRyPKCQIyIi4lzHyxV6SsrJO1ThDEWHytmbV8q2nCK2ZRexN7/6DM9VAvysdIhyruLepZUv/Xy306nsNyKi4/AbcL1X663L3+86rDAmIiIiTV2Anw8Bfj7EnmAm5uKySrbnFLut67U1u4id+4sprXDw274CfttXcPhoX6A3HaKC+WFAvf8KJ6SQIyIiIscUbPOlV9twerUNd9tfaXeQfqCEbTnuq7pvyy6iQ3SwSdW6U8gRERGRWvP1sdIhOoQO0SGc0/3I7MqGYXCowm5iZUfUcYlUERERkeosFgtB/o3jHopCjoiIiDRLCjkiIiLSLCnkiIiISLOkkCMiIiLNkkKOiIiINEsKOSIiItIsKeSIiIhIs6SQIyIiIs2SQo6IiIg0Swo5IiIi0iwp5IiIiEizpJAjIiIizZJCjoiIiDRLjWOZ0AZkGAYABQUFJlciIiIinqr6u131d9wTLS7kFBYWApCYmGhyJSIiIlJbhYWFhIeHe3SsxahNJGoGHA4He/fuJTQ0FIvF4tX3LigoIDExkYyMDMLCwrz63s2Zrlvt6ZrVja5b3ei61Y2uW+0d75oZhkFhYSEJCQlYrZ71tmlxd3KsVitt27at188ICwvTF7oOdN1qT9esbnTd6kbXrW503WrvWNfM0zs4VdTxWERERJolhRwRERFplhRyvMhmszFlyhRsNpvZpTQpum61p2tWN7pudaPrVje6brXn7WvW4joei4iISMugOzkiIiLSLCnkiIiISLOkkCMiIiLNkkKOiIiINEsKOV7y6quvkpycTEBAAKmpqSxfvtzskhq1xx9/HIvF4rZ17drV7LIanSVLljBmzBgSEhKwWCzMnj3b7XXDMHjssceIj48nMDCQESNGsGXLFnOKbUROdN2uu+66at+/UaNGmVNsIzF16lQGDBhAaGgoMTExXHzxxWzevNntmNLSUiZMmEDr1q0JCQnhsssuIysry6SKGwdPrtuwYcOqfd9uvfVWkypuHF5//XV69+7tmvRv0KBBfP/9967XvfVdU8jxgpkzZzJx4kSmTJnCqlWrSElJYeTIkWRnZ5tdWqPWo0cP9u3b59qWLl1qdkmNTnFxMSkpKbz66qs1vv7888/z8ssv88Ybb/Drr78SHBzMyJEjKS0tbeBKG5cTXTeAUaNGuX3/Pv744wassPFZvHgxEyZM4JdffmH+/PlUVFRw7rnnUlxc7Drm3nvv5ZtvvuGzzz5j8eLF7N27l0svvdTEqs3nyXUDuOmmm9y+b88//7xJFTcObdu25dlnn2XlypWsWLGCs846i4suuogNGzYAXvyuGXLSBg4caEyYMMH13G63GwkJCcbUqVNNrKpxmzJlipGSkmJ2GU0KYHz55Zeu5w6Hw4iLizNeeOEF1768vDzDZrMZH3/8sQkVNk5/vG6GYRjjx483LrroIlPqaSqys7MNwFi8eLFhGM7vlp+fn/HZZ5+5jtm4caMBGMuWLTOrzEbnj9fNMAxj6NChxt13321eUU1EZGSk8Y9//MOr3zXdyTlJ5eXlrFy5khEjRrj2Wa1WRowYwbJly0ysrPHbsmULCQkJdOjQgWuuuYb09HSzS2pSduzYQWZmptt3Lzw8nNTUVH33PLBo0SJiYmLo0qULt912G/v37ze7pEYlPz8fgFatWgGwcuVKKioq3L5vXbt2pV27dvq+HeWP163Khx9+SFRUFD179mTy5MmUlJSYUV6jZLfb+eSTTyguLmbQoEFe/a61uAU6vS03Nxe73U5sbKzb/tjYWDZt2mRSVY1famoq7777Ll26dGHfvn088cQTnHnmmaxfv57Q0FCzy2sSMjMzAWr87lW9JjUbNWoUl156Ke3bt2fbtm089NBDjB49mmXLluHj42N2eaZzOBzcc889DB48mJ49ewLO75u/vz8RERFux+r7dkRN1w3g6quvJikpiYSEBNauXcuDDz7I5s2b+eKLL0ys1nzr1q1j0KBBlJaWEhISwpdffkn37t1JS0vz2ndNIUdMMXr0aNfj3r17k5qaSlJSEp9++il/+ctfTKxMWoIrr7zS9bhXr1707t2bjh07smjRIs4++2wTK2scJkyYwPr169VPrpaOdd1uvvlm1+NevXoRHx/P2WefzbZt2+jYsWNDl9lodOnShbS0NPLz85k1axbjx49n8eLFXv0MNVedpKioKHx8fKr1+s7KyiIuLs6kqpqeiIgIOnfuzNatW80upcmo+n7pu3fyOnToQFRUlL5/wB133MG3337Ljz/+SNu2bV374+LiKC8vJy8vz+14fd+cjnXdapKamgrQ4r9v/v7+dOrUif79+zN16lRSUlL4+9//7tXvmkLOSfL396d///4sXLjQtc/hcLBw4UIGDRpkYmVNS1FREdu2bSM+Pt7sUpqM9u3bExcX5/bdKygo4Ndff9V3r5Z2797N/v37W/T3zzAM7rjjDr788kt++OEH2rdv7/Z6//798fPzc/u+bd68mfT09Bb9fTvRdatJWloaQIv+vtXE4XBQVlbm3e+ad/tGt0yffPKJYbPZjHfffdf47bffjJtvvtmIiIgwMjMzzS6t0brvvvuMRYsWGTt27DB++uknY8SIEUZUVJSRnZ1tdmmNSmFhobF69Wpj9erVBmBMmzbNWL16tbFr1y7DMAzj2WefNSIiIoyvvvrKWLt2rXHRRRcZ7du3Nw4dOmRy5eY63nUrLCw07r//fmPZsmXGjh07jAULFhj9+vUzTjnlFKO0tNTs0k1z2223GeHh4caiRYuMffv2ubaSkhLXMbfeeqvRrl0744cffjBWrFhhDBo0yBg0aJCJVZvvRNdt69atxpNPPmmsWLHC2LFjh/HVV18ZHTp0MIYMGWJy5eaaNGmSsXjxYmPHjh3G2rVrjUmTJhkWi8WYN2+eYRje+64p5HjJK6+8YrRr187w9/c3Bg4caPzyyy9ml9SojR071oiPjzf8/f2NNm3aGGPHjjW2bt1qdlmNzo8//mgA1bbx48cbhuEcRv7oo48asbGxhs1mM84++2xj8+bN5hbdCBzvupWUlBjnnnuuER0dbfj5+RlJSUnGTTfd1OL/p6Sm6wUY//rXv1zHHDp0yLj99tuNyMhIIygoyLjkkkuMffv2mVd0I3Ci65aenm4MGTLEaNWqlWGz2YxOnToZDzzwgJGfn29u4Sa74YYbjKSkJMPf39+Ijo42zj77bFfAMQzvfdcshmEYdbyzJCIiItJoqU+OiIiINEsKOSIiItIsKeSIiIhIs6SQIyIiIs2SQo6IiIg0Swo5IiIi0iwp5IiIiEizpJAjIlKD5ORkpk+fbnYZInISFHJEpN7k5OTg7+9PcXExFRUVBAcHk56eftxzHn/8cSwWS7Wta9euDVS1iDQXvmYXICLN17Jly0hJSSE4OJhff/2VVq1a0a5duxOe16NHDxYsWOC2z9dX/7kSkdrRnRwRqTc///wzgwcPBmDp0qWuxyfi6+tLXFyc2xYVFeV6PTk5mb/+9a9cddVVBAcH06ZNG1599VW390hPT+eiiy4iJCSEsLAwrrjiCrKystyO+eabbxgwYAABAQFERUVxySWXuL1eUlLCDTfcQGhoKO3ateOtt95yvVZeXs4dd9xBfHw8AQEBJCUlMXXq1FpdHxGpXwo5IuJV6enpREREEBERwbRp03jzzTeJiIjgoYceYvbs2URERHD77bef9Oe88MILpKSksHr1aiZNmsTdd9/N/PnzAXA4HFx00UUcOHCAxYsXM3/+fLZv387YsWNd53/33XdccsklnHfeeaxevZqFCxcycOBAt8948cUXOfXUU1m9ejW33347t912G5s3bwbg5Zdf5uuvv+bTTz9l8+bNfPjhhyQnJ5/07yUiXuS9NUVFRAyjoqLC2LFjh7FmzRrDz8/PWLNmjbF161YjJCTEWLx4sbFjxw4jJyfnmOdPmTLFsFqtRnBwsNt2yy23uI5JSkoyRo0a5Xbe2LFjjdGjRxuGYRjz5s0zfHx8jPT0dNfrGzZsMABj+fLlhmEYxqBBg4xrrrnmmHUkJSUZf/7zn13PHQ6HERMTY7z++uuGYRjGnXfeaZx11lmGw+GoxdURkYakOzki4lW+vr4kJyezadMmBgwYQO/evcnMzCQ2NpYhQ4aQnJzs1vRUky5dupCWlua2Pfnkk27HDBo0qNrzjRs3ArBx40YSExNJTEx0vd69e3ciIiJcx6SlpXH22Wcft47evXu7HlssFuLi4sjOzgbguuuuIy0tjS5dunDXXXcxb968E1wZEWlo6sknIl7Vo0cPdu3aRUVFBQ6Hg5CQECorK6msrCQkJISkpCQ2bNhw3Pfw9/enU6dO9VpnYGDgCY/x8/Nze26xWHA4HAD069ePHTt28P3337NgwQKuuOIKRowYwaxZs+qlXhGpPd3JERGvmjNnDmlpacTFxfHBBx+QlpZGz549mT59OmlpacyZM8crn/PLL79Ue96tWzcAunXrRkZGBhkZGa7Xf/vtN/Ly8ujevTvgvEuzcOHCk6ohLCyMsWPH8vbbbzNz5kw+//xzDhw4cFLvKSLeozs5IuJVSUlJZGZmkpWVxUUXXYTFYmHDhg1cdtllxMfHe/QelZWVZGZmuu2zWCzExsa6nv/00088//zzXHzxxcyfP5/PPvuM7777DoARI0bQq1cvrrnmGqZPn05lZSW33347Q4cO5dRTTwVgypQpnH322XTs2JErr7ySyspK5syZw4MPPuhRjdOmTSM+Pp6+fftitVr57LPPiIuLIyIiwqPzRaT+6U6OiHjdokWLXEOzly9fTtu2bT0OOAAbNmwgPj7ebUtKSnI75r777mPFihX07duXp556imnTpjFy5EjAGYi++uorIiMjGTJkCCNGjKBDhw7MnDnTdf6wYcP47LPP+Prrr+nTpw9nnXUWy5cv97jG0NBQnn/+eU499VQGDBjAzp07mTNnDlar/rMq0lhYDMMwzC5CRKQ2kpOTueeee7jnnnvMLkVEGjH9L4eIiIg0Swo5IiIi0iypuUpERESaJd3JERERkWZJIUdERESaJYUcERERaZYUckRERKRZUsgRERGRZkkhR0RERJolhRwRERFplhRyREREpFlSyBEREZFm6f8BOYxTWucNNGgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# example numbers\n",
    "para = [0.709, 0.631, 0.590, 0.553, 0.524, 0.493, 0.457, 0.439, 0.411, 0.379, 0.371, 0.338, 0.331, 0.312, 0.301, 0.292, 0.256, 0.255, 0.250, 0.242, 0.241, 0.247, 0.211, 0.205, 0.195, 0.187, 0.175, 0.154, 0.151, 0.138]\n",
    "sts = [1.357, 0.772, 0.605, 0.520, 0.440, 0.394, 0.357, 0.339, 0.302, 0.290, 0.275, 0.259, 0.252, 0.245, 0.238, 0.224, 0.222, 0.216, 0.206, 0.206, 0.203, 0.198, 0.191, 0.186, 0.177, 0.164, 0.152, 0.142, 0.138, 0.129]\n",
    "\n",
    "plot_loss(sts, para, \"Non-Multitask Model\", \"./plots/nonmultitask.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
