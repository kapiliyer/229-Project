{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from random import sample\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "for folder in ['multitask', 'para_single', 'sts_single', 'multitask_pcgrad']:\n",
    "    try:\n",
    "        os.mkdir('./models/' + folder)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "sts_train = pd.read_csv('./data/sts-train.csv', sep=\"\\t\")\n",
    "sts_train = sts_train.dropna()\n",
    "\n",
    "para_train = pd.read_csv('./data/quora-train.csv', sep=\"\\t\")\n",
    "para_train = para_train.dropna()[:len(sts_train)]\n",
    "\n",
    "sts_dev = pd.read_csv('./data/sts-dev.csv', sep=\"\\t\")\n",
    "sts_dev = sts_dev.dropna() \n",
    "\n",
    "para_dev = pd.read_csv('./data/quora-dev.csv', sep=\"\\t\")\n",
    "para_dev = para_dev.dropna()[:len(sts_dev)]\n",
    "\n",
    "para_dev, para_test = para_dev[:(para_dev.shape[0] // 2)], para_dev[(para_dev.shape[0] // 2):]\n",
    "sts_dev, sts_test = sts_dev[:(sts_dev.shape[0] // 2)], sts_dev[(sts_dev.shape[0] // 2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cs229/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "# sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "# model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "# embeddings = model.encode(sentences)\n",
    "# print(embeddings)\n",
    "# print(para_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "N_PARAPHRASE_CLASSES = 1\n",
    "N_SIMILARITY_CLASSES = 1\n",
    "DROPOUT_PROB = 0.5\n",
    "INPUT_SIZE = 768\n",
    "\n",
    "class NLP_Model(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(NLP_Model, self).__init__()\n",
    "        self.model = model\n",
    "        self.dropout = nn.Dropout(DROPOUT_PROB)\n",
    "        self.paraphrase_linear = nn.Linear(INPUT_SIZE, INPUT_SIZE // 2)\n",
    "        self.paraphrase_linear_interact = nn.Linear(INPUT_SIZE, N_PARAPHRASE_CLASSES)\n",
    "        self.similarity_linear = nn.Linear(INPUT_SIZE, INPUT_SIZE // 2)\n",
    "        self.similarity_linear_interact = nn.Linear(INPUT_SIZE, N_SIMILARITY_CLASSES)\n",
    "    \n",
    "    def forward(self, sentences1, sentences2, task, device):\n",
    "        '''\n",
    "        Task 0 is para. Task 1 is similarity.\n",
    "        '''\n",
    "        sentences1 = torch.as_tensor(self.model.encode(sentences1.tolist()))\n",
    "        sentences1 = sentences1.to(device)\n",
    "        sentences2 = torch.as_tensor(self.model.encode(sentences2.tolist()))\n",
    "        sentences2 = sentences2.to(device)\n",
    "        if task == 0:\n",
    "            sentences1 = self.dropout(sentences1)\n",
    "            sentences1 = F.relu(self.paraphrase_linear(sentences1))\n",
    "            sentences2 = self.dropout(sentences2)\n",
    "            sentences2 = F.relu(self.paraphrase_linear(sentences2))\n",
    "            combined = torch.concat((sentences1, sentences2), dim=-1)\n",
    "            combined = self.dropout(combined)\n",
    "            return F.sigmoid(self.paraphrase_linear_interact(combined))\n",
    "        if task == 1:\n",
    "            sentences1 = self.dropout(sentences1)\n",
    "            sentences1 = F.relu(self.similarity_linear(sentences1))\n",
    "            sentences2 = self.dropout(sentences2)\n",
    "            sentences2 = F.relu(self.similarity_linear(sentences2))\n",
    "            combined = torch.concat((sentences1, sentences2), dim=-1)\n",
    "            combined = self.dropout(combined)\n",
    "            return F.sigmoid(self.similarity_linear_interact(combined)) * 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "def save_model(model, optimizer, filepath):\n",
    "    save_info = {\n",
    "        'model': model.state_dict(),\n",
    "        'optim': optimizer.state_dict(),\n",
    "        'system_rng': random.getstate(),\n",
    "        'numpy_rng': np.random.get_state(),\n",
    "        'torch_rng': torch.random.get_rng_state(),\n",
    "    }\n",
    "\n",
    "    torch.save(save_info, f'{filepath}/model')\n",
    "    model.model.save(f'{filepath}/transformer')\n",
    "    print(f\"saved the model to {filepath}\")\n",
    "\n",
    "def load_model(filepath, device):\n",
    "    with torch.no_grad():\n",
    "        save_info = torch.load(f'{filepath}/model')\n",
    "        transformer_model = SentenceTransformer(f'{filepath}/transformer')\n",
    "        transformer_model.to(device)\n",
    "        \n",
    "        model = NLP_Model(transformer_model)\n",
    "        model.load_state_dict(save_info['model'])\n",
    "        model.to(device)\n",
    "        \n",
    "        optimizer = AdamW(list(model.parameters()) + list(transformer_model.parameters()), lr=1e-4)\n",
    "        optimizer.load_state_dict(save_info['optim'])\n",
    "        \n",
    "        random.setstate(save_info['system_rng'])\n",
    "        np.random.set_state(save_info['numpy_rng'])\n",
    "        torch.random.set_rng_state(save_info['torch_rng'])\n",
    "    return model, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "def get_batches(dataset, batch_size=512):\n",
    "    \"\"\"\n",
    "    Pass in dataset and batch size.\n",
    "    Get generator which yields batches.\n",
    "    \"\"\"\n",
    "    return enumerate(dataset[i*batch_size:(i+1)*batch_size] for i in range(ceil(dataset.shape[0] / batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "def train_singletask_para_model(para_train, para_dev, filepath):\n",
    "    '''\n",
    "    use AdamW optimizer.\n",
    "    binary cross-entropy loss.\n",
    "    make sure to save model at end to a specific path.\n",
    "    '''\n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "    transformer = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "    transformer.to(device)\n",
    "\n",
    "    model = NLP_Model(transformer)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = AdamW(list(model.parameters()) + list(transformer.parameters()), lr=1e-2) #~SGD with weight decay 0.01\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'max')\n",
    "\n",
    "    best_dev_acc = 0\n",
    "\n",
    "    train_para_accuracy = eval_singletask_model(model, device, para_train, 0, 'train')\n",
    "    dev_para_accuracy = eval_singletask_model(model, device, para_dev, 0, 'dev')\n",
    "    print(f\"epoch number: 0, para train accuracy: {train_para_accuracy}, para dev accuracy: {dev_para_accuracy}\")\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        transformer.train()\n",
    "\n",
    "        for step, batch in tqdm(get_batches(para_train), desc='train'):\n",
    "            b_sentences1, b_sentences2, b_labels = batch['sentence1'], batch['sentence2'], batch['is_duplicate']\n",
    "            optimizer.zero_grad()\n",
    "            logits = model.forward(b_sentences1, b_sentences2, 0, device).flatten()\n",
    "\n",
    "            b_labels = torch.as_tensor(b_labels.values, dtype=torch.float32)\n",
    "            b_labels = b_labels.to(device)\n",
    "\n",
    "            loss = F.binary_cross_entropy(logits, b_labels, reduction='mean')\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_para_accuracy = eval_singletask_model(model, device, para_train, 0, 'train')\n",
    "        dev_para_accuracy = eval_singletask_model(model, device, para_dev, 0, 'dev')\n",
    "        print(f\"epoch number: {epoch + 1}, para train accuracy: {train_para_accuracy}, para dev accuracy: {dev_para_accuracy}\")\n",
    "\n",
    "        scheduler.step(dev_para_accuracy)\n",
    "\n",
    "        if dev_para_accuracy >= best_dev_acc:\n",
    "            best_dev_acc = dev_para_accuracy\n",
    "            print('New best model. Saving.')\n",
    "            save_model(model, optimizer, filepath)\n",
    "\n",
    "\n",
    "def train_singletask_sts_model(sts_train, sts_dev, filepath):\n",
    "    '''\n",
    "    use AdamW optimizer.\n",
    "    multi-class cross-entropy loss.\n",
    "    make sure to save model at end to a specific path.\n",
    "    '''\n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "    transformer = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "    transformer.to(device)\n",
    "\n",
    "    model = NLP_Model(transformer)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = AdamW(list(model.parameters()) + list(transformer.parameters()), lr=1e-2) #~SGD with weight decay 0.01\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'max')\n",
    "\n",
    "    best_dev_acc = 0\n",
    "\n",
    "    train_sts_acc = eval_singletask_model(model, device, sts_train, 1, 'train')\n",
    "    dev_sts_acc = eval_singletask_model(model, device, sts_dev, 1, 'dev')\n",
    "    print(f\"epoch number: 0, sts train accuracy: {train_sts_acc}, sts dev accuracy: {dev_sts_acc}\")\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        transformer.train()\n",
    "\n",
    "        for step, batch in tqdm(get_batches(sts_train), desc='train'):\n",
    "            b_sentences1, b_sentences2, b_labels = batch['sentence1'], batch['sentence2'], batch['similarity']\n",
    "            optimizer.zero_grad()\n",
    "            logits = model.forward(b_sentences1, b_sentences2, 1, device).flatten()\n",
    "\n",
    "            b_labels = torch.as_tensor(b_labels.values, dtype=torch.float32)\n",
    "            b_labels = b_labels.to(device)\n",
    "\n",
    "            loss = F.mse_loss(logits, b_labels, reduction='mean')\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_sts_acc = eval_singletask_model(model, device, sts_train, 1, 'train')\n",
    "        dev_sts_acc = eval_singletask_model(model, device, sts_dev, 1, 'dev')\n",
    "        print(f\"epoch number: {epoch + 1}, sts train accuracy: {train_sts_acc}, sts dev accuracy: {dev_sts_acc}\")\n",
    "\n",
    "        scheduler.step(dev_sts_acc)\n",
    "\n",
    "        if dev_sts_acc >= best_dev_acc:\n",
    "            best_dev_acc = dev_sts_acc\n",
    "            print('New best model. Saving.')\n",
    "            save_model(model, optimizer, filepath)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/docs/transformers/training#train-in-native-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_singletask_model(model, device, dataset, task, flag):\n",
    "    '''\n",
    "    given dataloader, 2 task-specific finetuned models, and device\n",
    "    return the accuracy for para and for sts\n",
    "    '''\n",
    "    model.eval()\n",
    "    model.model.eval()\n",
    "    with torch.no_grad():\n",
    "        truth = []\n",
    "        predictions = []\n",
    "        for step, batch in tqdm(get_batches(dataset), desc=f\"{flag} eval\"):\n",
    "            b_sentences1, b_sentences2, b_labels = batch['sentence1'], batch['sentence2'], batch['is_duplicate' if task == 0 else 'similarity']\n",
    "            truth.extend(b_labels)\n",
    "            logits = model.forward(b_sentences1, b_sentences2, task, device)\n",
    "            logits = logits.detach().cpu().numpy().flatten()\n",
    "            if task == 0:\n",
    "                new_predictions = np.round(logits).flatten()\n",
    "            else:\n",
    "                new_predictions = logits.flatten()\n",
    "            predictions.extend(new_predictions)\n",
    "        if task == 0:\n",
    "            accuracy = (np.array(truth).flatten() == np.array(predictions).flatten()).mean()\n",
    "        else:\n",
    "            accuracy = (np.round(np.array(truth).flatten()) == np.round(np.array(predictions).flatten())).mean()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcgrad import PCGrad\n",
    "\n",
    "def train_multitask_model(para_train, para_dev, sts_train, sts_dev, filepath, pcgrad_flag):\n",
    "    '''\n",
    "    use AdamW optimizer.\n",
    "    binary cross-entropy loss for para, multi-class cross-entropy loss for sts, sum loss functions. \n",
    "    make sure to save model at end to a specific path.\n",
    "    '''\n",
    "    device = torch.device('cuda')\n",
    "    \n",
    "    transformer = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "    transformer.to(device)\n",
    "\n",
    "    model = NLP_Model(transformer)\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = AdamW(list(model.parameters()) + list(transformer.parameters()), lr=1e-2) #~SGD with weight decay 0.01\n",
    "    scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
    "    if pcgrad_flag: optimizer = PCGrad(optimizer)\n",
    "\n",
    "    best_dev_acc = 0\n",
    "\n",
    "    train_para_acc = eval_singletask_model(model, device, para_train, 0, 'train')\n",
    "    dev_para_acc = eval_singletask_model(model, device, para_dev, 0, 'dev')\n",
    "    train_sts_acc = eval_singletask_model(model, device, sts_train, 1, 'train')\n",
    "    dev_sts_acc = eval_singletask_model(model, device, sts_dev, 1, 'dev')\n",
    "    print(f\"epoch number: 0, para train accuracy: {train_para_acc}, para dev accuracy: {dev_para_acc}, sts train accuracy: {train_sts_acc}, sts dev accuracy: {dev_sts_acc}\")\n",
    "\n",
    "    train_acc = (train_para_acc + train_sts_acc) / 2\n",
    "    dev_acc = (dev_para_acc + dev_sts_acc) / 2\n",
    "    print(f\"epoch number: 0, avg train accuracy: {train_acc}, avg dev accuracy: {dev_acc}\")\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        transformer.train()\n",
    "\n",
    "        for (para_step, para_batch), (sts_step, sts_batch) in zip(tqdm(get_batches(para_train), desc='train'), tqdm(get_batches(sts_train), desc='train')):\n",
    "            b_para_sentences1, b_para_sentences2, b_para_labels = para_batch['sentence1'], para_batch['sentence2'], para_batch['is_duplicate']\n",
    "            b_sts_sentences1, b_sts_sentences2, b_sts_labels = sts_batch['sentence1'], sts_batch['sentence2'], sts_batch['similarity']\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            para_logits = model.forward(b_para_sentences1, b_para_sentences2, 0, device).flatten()\n",
    "            sts_logits = model.forward(b_sts_sentences1, b_sts_sentences2, 1, device).flatten()\n",
    "\n",
    "            b_para_labels = torch.as_tensor(b_para_labels.values, dtype=torch.float32)\n",
    "            b_para_labels = b_para_labels.to(device)\n",
    "            b_sts_labels = torch.as_tensor(b_sts_labels.values, dtype=torch.float32)\n",
    "            b_sts_labels = b_sts_labels.to(device)\n",
    "\n",
    "            loss = (F.binary_cross_entropy(para_logits, b_para_labels, reduction='mean') + F.mse_loss(sts_logits, b_sts_labels, reduction='mean')) / 2\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        train_para_acc = eval_singletask_model(model, device, para_train, 0, 'train')\n",
    "        dev_para_acc = eval_singletask_model(model, device, para_dev, 0, 'dev')\n",
    "        train_sts_acc = eval_singletask_model(model, device, sts_train, 1, 'train')\n",
    "        dev_sts_acc = eval_singletask_model(model, device, sts_dev, 1, 'dev')\n",
    "        print(f\"epoch number: {epoch + 1}, para train accuracy: {train_para_acc}, para dev accuracy: {dev_para_acc}, sts train accuracy: {train_sts_acc}, sts dev accuracy: {dev_sts_acc}\")\n",
    "\n",
    "        train_acc = (train_para_acc + train_sts_acc) / 2\n",
    "        dev_acc = (dev_para_acc + dev_sts_acc) / 2\n",
    "        print(f\"epoch number: {epoch + 1}, avg train accuracy: {train_acc}, avg dev accuracy: {dev_acc}\")\n",
    "\n",
    "        scheduler.step(dev_acc, 'max')\n",
    "\n",
    "        if dev_acc >= best_dev_acc:\n",
    "            best_dev_acc = dev_acc\n",
    "            print('New best model. Saving.')\n",
    "            save_model(model, optimizer, filepath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_singletask_model(filepath1, filepath2):\n",
    "    train_singletask_para_model(para_train, para_dev, filepath1)\n",
    "    train_singletask_sts_model(sts_train, sts_dev, filepath2)\n",
    "\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "    para_model, _ = load_model(filepath1, device)\n",
    "    sts_model, _ = load_model(filepath2, device)\n",
    "\n",
    "    para_acc = eval_singletask_model(para_model, device, para_test, 0, 'test')\n",
    "    sts_acc = eval_singletask_model(sts_model, device, sts_test, 1, 'test')\n",
    "\n",
    "    print(f'Final test accuracy. PARA: {para_acc}, STS: {sts_acc}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/cs229/lib/python3.11/site-packages/torch/optim/adamw.py:50: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
      "  super().__init__(params, defaults)\n",
      "train eval: 12it [00:16,  1.37s/it]\n",
      "dev eval: 1it [00:01,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 0, para train accuracy: 0.6301324503311259, para dev accuracy: 0.6218097447795824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 12it [00:16,  1.34s/it]\n",
      "train eval: 12it [00:16,  1.36s/it]\n",
      "dev eval: 1it [00:01,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 1, para train accuracy: 0.722682119205298, para dev accuracy: 0.6682134570765661\n",
      "New best model. Saving.\n",
      "saved the model to ./models/para_single\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 12it [00:16,  1.37s/it]\n",
      "train eval: 12it [00:16,  1.35s/it]\n",
      "dev eval: 1it [00:01,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 2, para train accuracy: 0.7518211920529801, para dev accuracy: 0.6705336426914154\n",
      "New best model. Saving.\n",
      "saved the model to ./models/para_single\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 12it [00:16,  1.36s/it]\n",
      "train eval: 12it [00:16,  1.36s/it]\n",
      "dev eval: 1it [00:01,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 3, para train accuracy: 0.7776490066225166, para dev accuracy: 0.6960556844547564\n",
      "New best model. Saving.\n",
      "saved the model to ./models/para_single\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 12it [00:16,  1.36s/it]\n",
      "train eval: 12it [00:16,  1.36s/it]\n",
      "dev eval: 1it [00:01,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 4, para train accuracy: 0.8072847682119205, para dev accuracy: 0.6937354988399071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 12it [00:16,  1.37s/it]\n",
      "train eval: 12it [00:16,  1.38s/it]\n",
      "dev eval: 1it [00:01,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 5, para train accuracy: 0.829635761589404, para dev accuracy: 0.7099767981438515\n",
      "New best model. Saving.\n",
      "saved the model to ./models/para_single\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 12it [00:16,  1.37s/it]\n",
      "train eval: 12it [00:16,  1.38s/it]\n",
      "dev eval: 1it [00:01,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 6, para train accuracy: 0.8481788079470198, para dev accuracy: 0.7215777262180975\n",
      "New best model. Saving.\n",
      "saved the model to ./models/para_single\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 12it [00:16,  1.38s/it]\n",
      "train eval: 12it [00:16,  1.38s/it]\n",
      "dev eval: 1it [00:01,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 7, para train accuracy: 0.8735099337748344, para dev accuracy: 0.703016241299304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 12it [00:16,  1.38s/it]\n",
      "train eval: 12it [00:16,  1.38s/it]\n",
      "dev eval: 1it [00:01,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 8, para train accuracy: 0.8910596026490066, para dev accuracy: 0.6960556844547564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 12it [00:16,  1.39s/it]\n",
      "train eval: 12it [00:16,  1.39s/it]\n",
      "dev eval: 1it [00:01,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 9, para train accuracy: 0.9124172185430464, para dev accuracy: 0.703016241299304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 12it [00:16,  1.39s/it]\n",
      "train eval: 12it [00:16,  1.39s/it]\n",
      "dev eval: 1it [00:01,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 10, para train accuracy: 0.9236754966887417, para dev accuracy: 0.6821345707656613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 12it [00:16,  1.40s/it]\n",
      "train eval: 12it [00:16,  1.41s/it]\n",
      "dev eval: 1it [00:01,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 11, para train accuracy: 0.9399006622516556, para dev accuracy: 0.6844547563805105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 12it [00:16,  1.40s/it]\n",
      "train eval: 12it [00:16,  1.39s/it]\n",
      "dev eval: 1it [00:01,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 12, para train accuracy: 0.9430463576158941, para dev accuracy: 0.691415313225058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 12it [00:16,  1.40s/it]\n",
      "train eval: 12it [00:16,  1.40s/it]\n",
      "dev eval: 1it [00:01,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 13, para train accuracy: 0.95, para dev accuracy: 0.691415313225058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 12it [00:16,  1.40s/it]\n",
      "train eval: 12it [00:16,  1.41s/it]\n",
      "dev eval: 1it [00:01,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 14, para train accuracy: 0.9496688741721855, para dev accuracy: 0.6890951276102089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 12it [00:17,  1.43s/it]\n",
      "train eval: 12it [00:17,  1.42s/it]\n",
      "dev eval: 1it [00:01,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 15, para train accuracy: 0.947682119205298, para dev accuracy: 0.6751740139211136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 12it [00:16,  1.41s/it]\n",
      "train eval: 12it [00:16,  1.41s/it]\n",
      "dev eval: 1it [00:01,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 16, para train accuracy: 0.9597682119205299, para dev accuracy: 0.6890951276102089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 12it [00:16,  1.41s/it]\n",
      "train eval: 12it [00:16,  1.41s/it]\n",
      "dev eval: 1it [00:01,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 17, para train accuracy: 0.9564569536423841, para dev accuracy: 0.6496519721577726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 12it [00:16,  1.41s/it]\n",
      "train eval: 12it [00:17,  1.42s/it]\n",
      "dev eval: 1it [00:01,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 18, para train accuracy: 0.9271523178807947, para dev accuracy: 0.6589327146171694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 12it [00:16,  1.41s/it]\n",
      "train eval: 12it [00:17,  1.42s/it]\n",
      "dev eval: 1it [00:01,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 19, para train accuracy: 0.9187086092715232, para dev accuracy: 0.642691415313225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 12it [00:16,  1.42s/it]\n",
      "train eval: 12it [00:17,  1.43s/it]\n",
      "dev eval: 1it [00:01,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 20, para train accuracy: 0.9177152317880795, para dev accuracy: 0.6357308584686775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train eval: 12it [00:15,  1.26s/it]\n",
      "dev eval: 1it [00:01,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 0, sts train acc: 0.2185430463576159, sts dev acc: 0.25986078886310904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 12it [00:15,  1.26s/it]\n",
      "train eval: 12it [00:15,  1.26s/it]\n",
      "dev eval: 1it [00:01,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 1, sts train acc: 0.23609271523178807, sts dev acc: 0.2691415313225058\n",
      "New best model. Saving.\n",
      "saved the model to ./models/sts_single\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 12it [00:15,  1.25s/it]\n",
      "train eval: 12it [00:15,  1.28s/it]\n",
      "dev eval: 1it [00:01,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 2, sts train acc: 0.24503311258278146, sts dev acc: 0.2482598607888631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 12it [00:15,  1.27s/it]\n",
      "train eval: 12it [00:15,  1.26s/it]\n",
      "dev eval: 1it [00:01,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 3, sts train acc: 0.26076158940397354, sts dev acc: 0.2459396751740139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 12it [00:15,  1.25s/it]\n",
      "train eval: 12it [00:15,  1.26s/it]\n",
      "dev eval: 1it [00:01,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 4, sts train acc: 0.27566225165562913, sts dev acc: 0.26218097447795824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 12it [00:15,  1.26s/it]\n",
      "train eval: 12it [00:15,  1.26s/it]\n",
      "dev eval: 1it [00:01,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 5, sts train acc: 0.2897350993377483, sts dev acc: 0.25986078886310904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 12it [00:15,  1.27s/it]\n",
      "train eval: 12it [00:15,  1.26s/it]\n",
      "dev eval: 1it [00:01,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 6, sts train acc: 0.302317880794702, sts dev acc: 0.2737819025522042\n",
      "New best model. Saving.\n",
      "saved the model to ./models/sts_single\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 6it [00:07,  1.26s/it]"
     ]
    }
   ],
   "source": [
    "test_singletask_model('./models/para_single', './models/sts_single')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_multitask_model(filepath, pcgrad_flag):\n",
    "    train_multitask_model(para_train, para_dev, sts_train, sts_dev, filepath, pcgrad_flag)\n",
    "\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "    model, _ = load_model(filepath, device)\n",
    "\n",
    "    para_acc = eval_singletask_model(model, device, para_test, 0, 'test')\n",
    "    sts_acc = eval_singletask_model(model, device, sts_test, 1, 'test')\n",
    "\n",
    "    print(f'Final test accuracy. PARA: {para_acc}, STS: {sts_acc}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_multitask_model('./models/multitask', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_multitask_model('./models/multitask_pcgrad', True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
