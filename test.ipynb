{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from random import sample\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "random.seed(0)\n",
    "para_train = pd.read_csv('./data/quora-train.csv', sep=\"\\t\")\n",
    "sts_train = pd.read_csv('./data/sts-train.csv', sep=\"\\t\")\n",
    "para_train = para_train.dropna()\n",
    "sts_train = sts_train.dropna()\n",
    "para_train = para_train.head(1000) #!!!!\n",
    "para_dev = pd.read_csv('./data/quora-dev.csv', sep=\"\\t\")\n",
    "sts_dev = pd.read_csv('./data/sts-dev.csv', sep=\"\\t\")\n",
    "para_dev = para_dev.dropna()\n",
    "para_dev = para_dev.head(10) #!!!!\n",
    "sts_dev = sts_dev.dropna() \n",
    "para_test = pd.read_csv('./data/quora-test-student.csv', sep=\"\\t\")\n",
    "sts_test = pd.read_csv('./data/sts-test-student.csv', sep=\"\\t\")\n",
    "para_test = para_test.dropna()\n",
    "sts_test = sts_test.dropna() \n",
    "# rand_data = sample(range(1, len(quora_df)-1), len(sts_df)-1)\n",
    "# rand_data.insert(0, 0)\n",
    "# quora_df_cut = pd.DataFrame([quora_df.iloc[i] for i in rand_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                         id  \\\n",
      "0      321296  a4da64a4e943bf8b008d174ca   \n",
      "1      373075  f965ab2d29d51008ab3872f47   \n",
      "2      213557  5aca073f4a977d55176f68572   \n",
      "3      209343  a8abbd08d3401287da42acfb9   \n",
      "4      389061  65dffaf8ac0ed7f3ebfcf0b02   \n",
      "\n",
      "                                           sentence1  \\\n",
      "0               How can I master myself in geometry?   \n",
      "1    Can deleted pictures on Instagram be recovered?   \n",
      "2  Who is the best prime minister India has ever ...   \n",
      "3  What qualifications do I need to get a job in ...   \n",
      "4              In what situations is it okay to lie?   \n",
      "\n",
      "                                           sentence2  is_duplicate  \n",
      "0          How can I master geometry for the CAT-14?           0.0  \n",
      "1            How do I delete a picture on Instagram?           0.0  \n",
      "2  Who is the best prime minister of the india ti...           1.0  \n",
      "3  What qualifications do I need to be able to wo...           1.0  \n",
      "4                            When is it okay to lie?           1.0  \n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "# sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "# model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "# embeddings = model.encode(sentences)\n",
    "# print(embeddings)\n",
    "print(para_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quora_1 = list(quora_df_cut['sentence1'])\n",
    "# quora_2 = list(quora_df_cut['sentence2'])\n",
    "# sts_1 = list(sts_df['sentence1'])\n",
    "# sts_2 = list(sts_df['sentence2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence_groups = [quora_1, quora_2, sts_1, sts_2]\n",
    "# embeddings = [model.encode(group, show_progress_bar=True) for group in sentence_groups]\n",
    "# quora_embeddings_1 = pd.DataFrame(embeddings[0])\n",
    "# quora_embeddings_2 = pd.DataFrame(embeddings[1])\n",
    "# sts_embeddings_1 = pd.DataFrame(embeddings[2])\n",
    "# sts_embeddings_2 = pd.DataFrame(embeddings[3])\n",
    "# quora_embeddings_1.to_csv(\"quora_embeddings_1.csv\")\n",
    "# quora_embeddings_2.to_csv(\"quora_embeddings_2.csv\")\n",
    "# sts_embeddings_1.to_csv(\"sts_embeddings_1.csv\")\n",
    "# sts_embeddings_2.to_csv(\"sts_embeddings_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data_utils\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "N_PARAPHRASE_CLASSES = 1\n",
    "N_SIMILARITY_CLASSES= 5\n",
    "DROPOUT_PROB = 0.5\n",
    "INPUT_SIZE = 768\n",
    "\n",
    "class NLP_Model(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(NLP_Model, self).__init__()\n",
    "        self.model = model\n",
    "        self.dropout = nn.Dropout(DROPOUT_PROB)\n",
    "        self.paraphrase_linear = nn.Linear(INPUT_SIZE, INPUT_SIZE // 2)\n",
    "        self.paraphrase_linear_interact = nn.Linear(INPUT_SIZE, N_PARAPHRASE_CLASSES)\n",
    "        self.similarity_linear = nn.Linear(INPUT_SIZE, INPUT_SIZE // 2)\n",
    "        self.similarity_linear_interact = nn.Linear(INPUT_SIZE, N_SIMILARITY_CLASSES)\n",
    "    \n",
    "    def forward(self, sentence1, sentence2, task, device):\n",
    "        '''\n",
    "        Task 0 is para. Task 1 is similarity.\n",
    "        '''\n",
    "        sentence1 = torch.from_numpy(self.model.encode(sentence1))\n",
    "        sentence1 = sentence1.to(device)\n",
    "        sentence2 = torch.from_numpy(self.model.encode(sentence2))\n",
    "        sentence2 = sentence2.to(device)\n",
    "        if task == 0:\n",
    "            sentence1 = self.dropout(sentence1)\n",
    "            sentence1 = F.relu(self.paraphrase_linear(sentence1))\n",
    "            sentence2 = self.dropout(sentence2)\n",
    "            sentence2 = F.relu(self.paraphrase_linear(sentence2))\n",
    "            combined = torch.concat((sentence1, sentence2), dim=-1)\n",
    "            combined = self.dropout(combined)\n",
    "            return F.sigmoid(self.paraphrase_linear_interact(combined))\n",
    "        if task == 1:\n",
    "            sentence1 = self.dropout(sentence1)\n",
    "            sentence1 = F.relu(self.similarity_linear(sentence1))\n",
    "            sentence2 = self.dropout(sentence2)\n",
    "            sentence2 = F.relu(self.similarity_linear(sentence2))\n",
    "            combined = torch.concat((sentence1, sentence2), dim=-1)\n",
    "            combined = self.dropout(combined)\n",
    "            return F.softmax(self.similarity_linear_interact(combined), dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, config, filepath):\n",
    "    save_info = {\n",
    "        'model': model.state_dict(),\n",
    "        'optim': optimizer.state_dict(),\n",
    "        'model_config': config,\n",
    "        'system_rng': random.getstate(),\n",
    "        'numpy_rng': np.random.get_state(),\n",
    "        'torch_rng': torch.random.get_rng_state(),\n",
    "    }\n",
    "\n",
    "    torch.save(save_info, filepath)\n",
    "    print(f\"save the model to {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "NUM_EPOCHS = 10\n",
    "\n",
    "def train_singletask_para_model(para_train, para_dev):\n",
    "    '''\n",
    "    use AdamW optimizer.\n",
    "    binary cross-entropy loss.\n",
    "    make sure to save model at end to a specific path.\n",
    "    '''\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "    #para_train_features = para_train[['sentence1', 'sentence2']]\n",
    "    #para_train_targets = para_train['is_duplicate']\n",
    "    #print(para_train_features.head())\n",
    "    #print(len(para_train_features), len(para_train_features.iloc[0]))\n",
    "    #para_train_features = torch.tensor(para_train_features.values)\n",
    "    #para_train_targets = torch.tensor(para_train_targets.values)\n",
    "    #para_train_data = data_utils.Dataset(para_train_features, para_train_targets)\n",
    "    #para_dev_features = para_dev[['sentence1', 'sentence2']]\n",
    "    #para_dev_targets = para_dev['is_duplicate']\n",
    "    #para_dev_features = torch.tensor(para_dev_features.values)\n",
    "    #para_dev_targets = torch.tensor(para_dev_targets.values)\n",
    "    #para_dev_data = data_utils.Dataset(para_dev_features, para_dev_targets)\n",
    "\n",
    "    #para_train_dataloader = DataLoader(para_train_data, shuffle=True, batch_size=16)\n",
    "    #para_dev_dataloader = DataLoader(para_dev_data, shuffle=True, batch_size=16)\n",
    "    \n",
    "    transformer = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "    transformer.to(device)\n",
    "    #transformer.train()\n",
    "\n",
    "    model = NLP_Model(transformer)\n",
    "    model = model.to(device)\n",
    "    #print(model.parameters())\n",
    "\n",
    "    optimizer = AdamW(list(model.parameters()) + list(transformer.parameters()), lr=5e-5) #SGD with weight decay 0.01\n",
    "    best_dev_acc = 0\n",
    "\n",
    "    train_para_accuracy = test_singletask_model(model, device, para_train, 0, 0)\n",
    "    dev_para_accuracy = test_singletask_model(model, device, para_dev, 0, 1)\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        #print(model.parameters())\n",
    "        model.train()\n",
    "        transformer.train()\n",
    "        train_loss = 0\n",
    "        num_batches = 0\n",
    "        #print('hello')\n",
    "        for step, batch in tqdm(para_train.iterrows(), desc='train'):\n",
    "            #print(batch)\n",
    "            b_sentence1, b_sentence2, b_labels = batch['sentence1'], batch['sentence2'], batch['is_duplicate']\n",
    "            optimizer.zero_grad()\n",
    "            logits = model.forward(b_sentence1, b_sentence2, 0, device)\n",
    "            #print(logits.size())\n",
    "            #predictions = np.round(logits).flatten()\n",
    "            b_labels = torch.tensor([b_labels])\n",
    "            b_labels = b_labels.to(device)\n",
    "            #print(b_labels.size())\n",
    "            loss = F.binary_cross_entropy(logits, b_labels, reduction='mean')\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            num_batches += 1\n",
    "        train_loss = train_loss / num_batches\n",
    "        train_para_accuracy = test_singletask_model(model, device, para_train, 0, 0)\n",
    "        dev_para_accuracy = test_singletask_model(model, device, para_dev, 0, 1)\n",
    "        print(f\"epoch number: {epoch + 1}, para train accuracy: {train_para_accuracy}, para dev accuracy: {dev_para_accuracy}\")\n",
    "    train_para_accuracy = test_singletask_model(model, device, para_train, 0, 0)\n",
    "    dev_para_accuracy = test_singletask_model(model, device, para_dev, 0, 1)\n",
    "    print(f\"epoch number: {NUM_EPOCHS + 1}, para train accuracy: {train_para_accuracy}, para dev accuracy: {dev_para_accuracy}\")\n",
    "\n",
    "     \n",
    "\n",
    "def train_singletask_sts_model():\n",
    "    '''\n",
    "    use AdamW optimizer.\n",
    "    multi-class cross-entropy loss.\n",
    "    make sure to save model at end to a specific path.\n",
    "    '''\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "    sts_train_dataloader = DataLoader(sts_train, shuffle=True, batch_size=16)\n",
    "    sts_dev_dataloader = DataLoader(sts_dev, shuffle=True, batch_size=16)\n",
    "    \n",
    "    transformer = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "    transformer.to(device)\n",
    "    #transformer.train()\n",
    "\n",
    "    pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/docs/transformers/training#train-in-native-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_singletask_model(model, device, dataset, task, dev_flag):\n",
    "    '''\n",
    "    given dataloader, 2 models, and device\n",
    "    return the accuracy for para and for sts\n",
    "    '''\n",
    "    model.eval()\n",
    "    model.model.eval()\n",
    "    with torch.no_grad():\n",
    "        #saved = torch.load(filepath)\n",
    "        #config = saved['model_config']\n",
    "        #model = NLP_Model(config, task)\n",
    "        #model.load_state_dict(saved['model'])\n",
    "        #model = model.to(device)\n",
    "        #para_saved = torch.load(para_filepath)\n",
    "        #sts_saved = torch.load(sts_filepath)\n",
    "        #para_config = para_saved['model_config']\n",
    "        #sts_config = sts_saved['model_config']\n",
    "        #para_model = NLP_Model(para_config, 0)\n",
    "        #sts_model = NLP_Model(sts_config, 1)\n",
    "        #para_model.load_state_dict(para_saved['model'])\n",
    "        #sts_model.load_state_dict(sts_saved['model'])\n",
    "        #para_model = para_model.to(device)\n",
    "        #sts_model = sts_model.to(device)\n",
    "        #print(f\"Loaded model\")\n",
    "\n",
    "        #para_test_dataloader = DataLoader(para_test, shuffle=True, batch_size=16)\n",
    "        #para_dev_dataloader = DataLoader(para_dev, shuffle=True, batch_size=16)\n",
    "        #sts_test_dataloader = DataLoader(sts_test, shuffle=True, batch_size=16)\n",
    "        #sts_dev_dataloader = DataLoader(sts_dev, shuffle=True, batch_size=16)\n",
    "        truth = []\n",
    "        predictions = []\n",
    "        for step, batch in tqdm(dataset.iterrows(), desc=f\"{'dev ' if dev_flag else 'train '}eval\"):\n",
    "            b_sentence1, b_sentence2, b_labels = batch['sentence1'], batch['sentence2'], batch['is_duplicate']\n",
    "            truth.extend([b_labels])\n",
    "            logits = model.forward(b_sentence1, b_sentence2, task, device)\n",
    "            logits = logits.detach().cpu().numpy()\n",
    "            if task == 0:\n",
    "                new_predictions = np.round(logits).flatten()\n",
    "            else:\n",
    "                new_predictions = np.argmax(logits, axis=1).flatten()\n",
    "            predictions.extend(new_predictions)\n",
    "        accuracy = (np.array(truth) == np.array(predictions)).mean()\n",
    "    return accuracy\n",
    "\n",
    "def train_multitask_model():\n",
    "    '''\n",
    "    use AdamW optimizer.\n",
    "    binary cross-entropy loss for para, multi-class cross-entropy loss for sts, sum loss functions. \n",
    "    make sure to save model at end to a specific path.\n",
    "    '''\n",
    "    pass \n",
    "\n",
    "def test_multitask_model():\n",
    "    '''\n",
    "    just accuracy for para.\n",
    "    accuracy + MSE for five class.\n",
    "    '''\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1000it [00:25, 39.25it/s]\n",
      "train eval: 1000it [00:23, 42.11it/s]\n",
      "dev eval: 10it [00:00, 42.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 1, para train accuracy: 0.64, para dev accuracy: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1000it [00:25, 39.84it/s]\n",
      "train eval: 1000it [00:23, 41.90it/s]\n",
      "dev eval: 10it [00:00, 42.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch number: 2, para train accuracy: 0.64, para dev accuracy: 0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train: 1000it [00:24, 40.33it/s]\n",
      "train eval: 717it [00:16, 42.30it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_28576/3419761817.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_singletask_para_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpara_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpara_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/tmp/ipykernel_28576/787858784.py\u001b[0m in \u001b[0;36mtrain_singletask_para_model\u001b[0;34m(para_train, para_dev)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mnum_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mtrain_para_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_singletask_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpara_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mdev_para_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_singletask_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpara_dev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"epoch number: {epoch + 1}, para train accuracy: {train_para_accuracy}, para dev accuracy: {dev_para_accuracy}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/tmp/ipykernel_28576/651662438.py\u001b[0m in \u001b[0;36mtest_singletask_model\u001b[0;34m(model, device, dataset, task, dev_flag)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mb_sentence1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_sentence2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sentence2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'is_duplicate'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mtruth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb_labels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_sentence1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_sentence2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/tmp/ipykernel_28576/2881344252.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentence1, sentence2, task, device)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mTask\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mpara\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mTask\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         '''\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0msentence1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0msentence1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0msentence2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sentence_transformers/SentenceTransformer.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_target_device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mall_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     def register_backward_hook(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    661\u001b[0m             \u001b[0;31m# track autograd history of `param_applied`, so we have to use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_singletask_para_model(para_train, para_dev)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
